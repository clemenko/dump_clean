ucp-kube-controller-manager
2018-06-21T20:58:14.037982171Z I0621 20:58:14.030772       1 controllermanager.go:109] Version: v1.8.11-docker-8d637ae
2018-06-21T20:58:14.088105107Z I0621 20:58:14.084714       1 leaderelection.go:174] attempting to acquire leader lease...
2018-06-21T20:58:14.124983543Z I0621 20:58:14.119371       1 leaderelection.go:184] successfully acquired lease kube-system/kube-controller-manager
2018-06-21T20:58:14.125006219Z I0621 20:58:14.119441       1 event.go:218] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"kube-controller-manager", UID:"1e44023a-7590-11e8-8955-0242ac110012", APIVersion:"v1", ResourceVersion:"3822", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' ip-172-31-9-58.ec2.internal became leader
2018-06-21T20:58:14.235470934Z I0621 20:58:14.233668       1 plugins.go:101] No cloud provider specified.
2018-06-21T20:58:14.237058392Z I0621 20:58:14.235896       1 controller_utils.go:1041] Waiting for caches to sync for tokens controller
2018-06-21T20:58:14.239636900Z I0621 20:58:14.237823       1 node_controller.go:249] Sending events to api server.
2018-06-21T20:58:14.239653785Z I0621 20:58:14.237967       1 taint_controller.go:158] Sending events to api server.
2018-06-21T20:58:14.239660656Z I0621 20:58:14.238055       1 controllermanager.go:491] Started "node"
2018-06-21T20:58:14.247008161Z I0621 20:58:14.240592       1 node_controller.go:515] Starting node controller
2018-06-21T20:58:14.247017932Z I0621 20:58:14.243875       1 controller_utils.go:1041] Waiting for caches to sync for node controller
2018-06-21T20:58:14.247023864Z I0621 20:58:14.244470       1 controllermanager.go:491] Started "replicationcontroller"
2018-06-21T20:58:14.247029596Z I0621 20:58:14.246523       1 replication_controller.go:151] Starting RC controller
2018-06-21T20:58:14.247035340Z I0621 20:58:14.246681       1 controller_utils.go:1041] Waiting for caches to sync for RC controller
2018-06-21T20:58:14.256972136Z I0621 20:58:14.254270       1 controllermanager.go:491] Started "serviceaccount"
2018-06-21T20:58:14.263420598Z I0621 20:58:14.257584       1 serviceaccounts_controller.go:113] Starting service account controller
2018-06-21T20:58:14.263438690Z I0621 20:58:14.257611       1 controller_utils.go:1041] Waiting for caches to sync for service account controller
2018-06-21T20:58:14.265370070Z I0621 20:58:14.262163       1 controllermanager.go:491] Started "horizontalpodautoscaling"
2018-06-21T20:58:14.265388060Z I0621 20:58:14.264306       1 horizontal.go:145] Starting HPA controller
2018-06-21T20:58:14.265395792Z I0621 20:58:14.264330       1 controller_utils.go:1041] Waiting for caches to sync for HPA controller
2018-06-21T20:58:14.265401809Z I0621 20:58:14.264690       1 controllermanager.go:491] Started "disruption"
2018-06-21T20:58:14.275198930Z I0621 20:58:14.267035       1 controllermanager.go:491] Started "statefulset"
2018-06-21T20:58:14.275217793Z I0621 20:58:14.268691       1 controllermanager.go:491] Started "cronjob"
2018-06-21T20:58:14.275225707Z W0621 20:58:14.268703       1 controllermanager.go:475] "tokencleaner" is disabled
2018-06-21T20:58:14.275232113Z I0621 20:58:14.269276       1 stateful_set.go:150] Starting stateful set controller
2018-06-21T20:58:14.275246179Z I0621 20:58:14.269298       1 disruption.go:288] Starting disruption controller
2018-06-21T20:58:14.275252911Z I0621 20:58:14.269299       1 controller_utils.go:1041] Waiting for caches to sync for stateful set controller
2018-06-21T20:58:14.275259054Z I0621 20:58:14.269308       1 controller_utils.go:1041] Waiting for caches to sync for disruption controller
2018-06-21T20:58:14.275264472Z I0621 20:58:14.269380       1 cronjob_controller.go:98] Starting CronJob Manager
2018-06-21T20:58:14.275269960Z W0621 20:58:14.271237       1 probe.go:215] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
2018-06-21T20:58:14.275276228Z E0621 20:58:14.271287       1 plugins.go:393] Error initializing dynamic plugin prober: Error (re-)creating driver directory: mkdir /usr/libexec: permission denied
2018-06-21T20:58:14.275282078Z I0621 20:58:14.271498       1 controllermanager.go:491] Started "attachdetach"
2018-06-21T20:58:14.275311315Z W0621 20:58:14.271514       1 controllermanager.go:488] Skipping "persistentvolume-expander"
2018-06-21T20:58:14.275317838Z I0621 20:58:14.273361       1 attach_detach_controller.go:255] Starting attach detach controller
2018-06-21T20:58:14.275323427Z I0621 20:58:14.273375       1 controller_utils.go:1041] Waiting for caches to sync for attach detach controller
2018-06-21T20:58:14.275329231Z I0621 20:58:14.273744       1 controllermanager.go:491] Started "podgc"
2018-06-21T20:58:14.279607116Z I0621 20:58:14.275383       1 gc_controller.go:76] Starting GC controller
2018-06-21T20:58:14.279625418Z I0621 20:58:14.275409       1 controller_utils.go:1041] Waiting for caches to sync for GC controller
2018-06-21T20:58:14.279633004Z W0621 20:58:14.275833       1 shared_informer.go:304] resyncPeriod 43503234410144 is smaller than resyncCheckPeriod 44106240607834 and the informer has already started. Changing it to 44106240607834
2018-06-21T20:58:14.279639315Z I0621 20:58:14.275899       1 controllermanager.go:491] Started "resourcequota"
2018-06-21T20:58:14.281364519Z I0621 20:58:14.278092       1 resource_quota_controller.go:238] Starting resource quota controller
2018-06-21T20:58:14.281382291Z I0621 20:58:14.278134       1 controller_utils.go:1041] Waiting for caches to sync for resource quota controller
2018-06-21T20:58:14.344989679Z I0621 20:58:14.336517       1 controller_utils.go:1048] Caches are synced for tokens controller
2018-06-21T20:58:14.366891804Z I0621 20:58:14.363213       1 controllermanager.go:491] Started "namespace"
2018-06-21T20:58:14.366993937Z I0621 20:58:14.365278       1 namespace_controller.go:186] Starting namespace controller
2018-06-21T20:58:14.367008412Z I0621 20:58:14.365293       1 controller_utils.go:1041] Waiting for caches to sync for namespace controller
2018-06-21T20:58:14.367015512Z I0621 20:58:14.365131       1 controllermanager.go:491] Started "ttl"
2018-06-21T20:58:14.367021475Z W0621 20:58:14.365401       1 controllermanager.go:475] "bootstrapsigner" is disabled
2018-06-21T20:58:14.367445396Z I0621 20:58:14.367055       1 ttl_controller.go:116] Starting TTL controller
2018-06-21T20:58:14.367461767Z I0621 20:58:14.367106       1 controller_utils.go:1041] Waiting for caches to sync for TTL controller
2018-06-21T20:58:14.367987512Z E0621 20:58:14.367681       1 core.go:70] Failed to start service controller: WARNING: no cloud provider provided, services of type LoadBalancer will fail.
2018-06-21T20:58:14.368002671Z W0621 20:58:14.367705       1 controllermanager.go:488] Skipping "service"
2018-06-21T20:58:14.368009041Z W0621 20:58:14.367716       1 core.go:128] Unsuccessful parsing of cluster CIDR : invalid CIDR address: 
2018-06-21T20:58:14.368014661Z I0621 20:58:14.367739       1 core.go:131] Will not configure cloud provider routes for allocate-node-cidrs: false, configure-cloud-routes: true.
2018-06-21T20:58:14.368020372Z W0621 20:58:14.367747       1 controllermanager.go:488] Skipping "route"
2018-06-21T20:58:14.370995558Z I0621 20:58:14.369678       1 controllermanager.go:491] Started "replicaset"
2018-06-21T20:58:14.374496522Z I0621 20:58:14.372042       1 replica_set.go:156] Starting replica set controller
2018-06-21T20:58:14.374514655Z I0621 20:58:14.372069       1 controller_utils.go:1041] Waiting for caches to sync for replica set controller
2018-06-21T20:58:14.374521799Z E0621 20:58:14.373752       1 certificates.go:48] Failed to start certificate controller: error reading CA cert file "/etc/kubernetes/ca/ca.pem": open /etc/kubernetes/ca/ca.pem: no such file or directory
2018-06-21T20:58:14.374528408Z W0621 20:58:14.373765       1 controllermanager.go:488] Skipping "csrsigning"
2018-06-21T20:58:14.378268004Z I0621 20:58:14.376019       1 controllermanager.go:491] Started "endpoint"
2018-06-21T20:58:14.378284726Z I0621 20:58:14.377794       1 endpoints_controller.go:153] Starting endpoint controller
2018-06-21T20:58:14.378291725Z I0621 20:58:14.377816       1 controller_utils.go:1041] Waiting for caches to sync for endpoint controller
2018-06-21T20:58:15.181687403Z I0621 20:58:15.181340       1 controllermanager.go:491] Started "garbagecollector"
2018-06-21T20:58:15.181716250Z I0621 20:58:15.181351       1 garbagecollector.go:136] Starting garbage collector controller
2018-06-21T20:58:15.181725002Z I0621 20:58:15.181383       1 controller_utils.go:1041] Waiting for caches to sync for garbage collector controller
2018-06-21T20:58:15.181731337Z I0621 20:58:15.181448       1 graph_builder.go:322] GraphBuilder running
2018-06-21T20:58:15.183125499Z I0621 20:58:15.182954       1 controllermanager.go:491] Started "daemonset"
2018-06-21T20:58:15.183498257Z I0621 20:58:15.183175       1 daemon_controller.go:230] Starting daemon sets controller
2018-06-21T20:58:15.183512754Z I0621 20:58:15.183202       1 controller_utils.go:1041] Waiting for caches to sync for daemon sets controller
2018-06-21T20:58:15.192170628Z I0621 20:58:15.191309       1 controllermanager.go:491] Started "job"
2018-06-21T20:58:15.193276537Z I0621 20:58:15.193030       1 job_controller.go:138] Starting job controller
2018-06-21T20:58:15.193295280Z I0621 20:58:15.193063       1 controller_utils.go:1041] Waiting for caches to sync for job controller
2018-06-21T20:58:15.193516830Z I0621 20:58:15.193324       1 controllermanager.go:491] Started "deployment"
2018-06-21T20:58:15.193696129Z I0621 20:58:15.193557       1 deployment_controller.go:151] Starting deployment controller
2018-06-21T20:58:15.193710556Z I0621 20:58:15.193590       1 controller_utils.go:1041] Waiting for caches to sync for deployment controller
2018-06-21T20:58:15.194993316Z I0621 20:58:15.194862       1 controllermanager.go:491] Started "csrapproving"
2018-06-21T20:58:15.195386538Z I0621 20:58:15.195227       1 certificate_controller.go:109] Starting certificate controller
2018-06-21T20:58:15.195402774Z I0621 20:58:15.195259       1 controller_utils.go:1041] Waiting for caches to sync for certificate controller
2018-06-21T20:58:15.199357764Z I0621 20:58:15.196505       1 controllermanager.go:491] Started "persistentvolume-binder"
2018-06-21T20:58:15.199375559Z I0621 20:58:15.197136       1 pv_controller_base.go:259] Starting persistent volume controller
2018-06-21T20:58:15.199382423Z I0621 20:58:15.197167       1 controller_utils.go:1041] Waiting for caches to sync for persistent volume controller
2018-06-21T20:58:15.238807099Z E0621 20:58:15.238384       1 actual_state_of_world.go:483] Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-10-96.ec2.internal"  does not exist
2018-06-21T20:58:15.238827737Z E0621 20:58:15.238401       1 actual_state_of_world.go:497] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-10-96.ec2.internal"  does not exist
2018-06-21T20:58:15.238835374Z E0621 20:58:15.238414       1 actual_state_of_world.go:483] Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-12-152.ec2.internal"  does not exist
2018-06-21T20:58:15.238841593Z E0621 20:58:15.238421       1 actual_state_of_world.go:497] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-12-152.ec2.internal"  does not exist
2018-06-21T20:58:15.238847945Z E0621 20:58:15.238543       1 actual_state_of_world.go:483] Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-18-229.ec2.internal"  does not exist
2018-06-21T20:58:15.238854079Z E0621 20:58:15.238552       1 actual_state_of_world.go:497] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-18-229.ec2.internal"  does not exist
2018-06-21T20:58:15.238860528Z E0621 20:58:15.238572       1 actual_state_of_world.go:483] Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-9-58.ec2.internal"  does not exist
2018-06-21T20:58:15.238866563Z E0621 20:58:15.238579       1 actual_state_of_world.go:497] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-9-58.ec2.internal"  does not exist
2018-06-21T20:58:15.252922560Z I0621 20:58:15.249454       1 controller_utils.go:1048] Caches are synced for RC controller
2018-06-21T20:58:15.257979384Z I0621 20:58:15.257808       1 controller_utils.go:1048] Caches are synced for service account controller
2018-06-21T20:58:15.264762888Z I0621 20:58:15.264580       1 controller_utils.go:1048] Caches are synced for HPA controller
2018-06-21T20:58:15.265719178Z I0621 20:58:15.265476       1 controller_utils.go:1048] Caches are synced for namespace controller
2018-06-21T20:58:15.267558839Z I0621 20:58:15.267321       1 controller_utils.go:1048] Caches are synced for TTL controller
2018-06-21T20:58:15.269761360Z I0621 20:58:15.269518       1 controller_utils.go:1048] Caches are synced for disruption controller
2018-06-21T20:58:15.269775044Z I0621 20:58:15.269532       1 disruption.go:296] Sending events to api server.
2018-06-21T20:58:15.269780753Z I0621 20:58:15.269602       1 controller_utils.go:1048] Caches are synced for stateful set controller
2018-06-21T20:58:15.272493781Z I0621 20:58:15.272264       1 controller_utils.go:1048] Caches are synced for replica set controller
2018-06-21T20:58:15.273729342Z I0621 20:58:15.273535       1 controller_utils.go:1048] Caches are synced for attach detach controller
2018-06-21T20:58:15.275769786Z I0621 20:58:15.275607       1 controller_utils.go:1048] Caches are synced for GC controller
2018-06-21T20:58:15.278977698Z I0621 20:58:15.278010       1 controller_utils.go:1048] Caches are synced for endpoint controller
2018-06-21T20:58:15.278994755Z I0621 20:58:15.278632       1 controller_utils.go:1048] Caches are synced for resource quota controller
2018-06-21T20:58:15.282171476Z I0621 20:58:15.281891       1 controller_utils.go:1048] Caches are synced for garbage collector controller
2018-06-21T20:58:15.282187734Z I0621 20:58:15.281909       1 garbagecollector.go:145] Garbage collector: all resource monitors have synced. Proceeding to collect garbage
2018-06-21T20:58:15.283574759Z I0621 20:58:15.283404       1 controller_utils.go:1048] Caches are synced for daemon sets controller
2018-06-21T20:58:15.295213549Z I0621 20:58:15.293496       1 controller_utils.go:1048] Caches are synced for job controller
2018-06-21T20:58:15.298762540Z I0621 20:58:15.298553       1 controller_utils.go:1048] Caches are synced for deployment controller
2018-06-21T20:58:15.306151206Z I0621 20:58:15.304130       1 controller_utils.go:1048] Caches are synced for persistent volume controller
2018-06-21T20:58:15.306169338Z I0621 20:58:15.304183       1 controller_utils.go:1048] Caches are synced for certificate controller
2018-06-21T20:58:15.344766179Z I0621 20:58:15.344336       1 controller_utils.go:1048] Caches are synced for node controller
2018-06-21T20:58:15.344784506Z I0621 20:58:15.344423       1 node_controller.go:567] Initializing eviction metric for zone: 
2018-06-21T20:58:15.345154368Z W0621 20:58:15.344517       1 node_controller.go:920] Missing timestamp for Node ip-172-31-10-96.ec2.internal. Assuming now as a timestamp.
2018-06-21T20:58:15.345171408Z I0621 20:58:15.344548       1 taint_controller.go:181] Starting NoExecuteTaintManager
2018-06-21T20:58:15.345179150Z W0621 20:58:15.344566       1 node_controller.go:920] Missing timestamp for Node ip-172-31-12-152.ec2.internal. Assuming now as a timestamp.
2018-06-21T20:58:15.345185234Z W0621 20:58:15.344601       1 node_controller.go:920] Missing timestamp for Node ip-172-31-18-229.ec2.internal. Assuming now as a timestamp.
2018-06-21T20:58:15.345203361Z W0621 20:58:15.344641       1 node_controller.go:920] Missing timestamp for Node ip-172-31-9-58.ec2.internal. Assuming now as a timestamp.
2018-06-21T20:58:15.345210325Z I0621 20:58:15.344673       1 node_controller.go:836] Controller detected that zone  is now in state Normal.
2018-06-21T20:58:15.345215616Z I0621 20:58:15.344740       1 event.go:218] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-172-31-10-96.ec2.internal", UID:"3239d323-7590-11e8-8955-0242ac110012", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node ip-172-31-10-96.ec2.internal event: Registered Node ip-172-31-10-96.ec2.internal in Controller
2018-06-21T20:58:15.345231364Z I0621 20:58:15.344762       1 event.go:218] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-172-31-9-58.ec2.internal", UID:"1e876bf6-7590-11e8-8955-0242ac110012", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node ip-172-31-9-58.ec2.internal event: Registered Node ip-172-31-9-58.ec2.internal in Controller
2018-06-21T20:58:15.345239476Z I0621 20:58:15.344775       1 event.go:218] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-172-31-12-152.ec2.internal", UID:"31a722e9-7590-11e8-8955-0242ac110012", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node ip-172-31-12-152.ec2.internal event: Registered Node ip-172-31-12-152.ec2.internal in Controller
2018-06-21T20:58:15.345248612Z I0621 20:58:15.344791       1 event.go:218] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-172-31-18-229.ec2.internal", UID:"31ca3f1d-7590-11e8-8955-0242ac110012", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node ip-172-31-18-229.ec2.internal event: Registered Node ip-172-31-18-229.ec2.internal in Controller
2018-06-21T20:58:19.687272894Z W0621 20:58:19.685591       1 reflector.go:334] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: watch of <nil> ended with: very short watch: k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.687296485Z W0621 20:58:19.685701       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.PodDisruptionBudget ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.687305445Z W0621 20:58:19.685817       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Service ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.687312799Z W0621 20:58:19.685902       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Job ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.687319572Z W0621 20:58:19.686020       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1alpha1.ExternalAdmissionHookConfiguration ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.687335243Z W0621 20:58:19.686105       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Secret ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.687344531Z W0621 20:58:19.686192       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Ingress ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.687351534Z W0621 20:58:19.686274       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.LimitRange ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.687358045Z W0621 20:58:19.686353       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.NetworkPolicy ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.688375499Z W0621 20:58:19.687514       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.StatefulSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.688405989Z W0621 20:58:19.687613       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.ControllerRevision ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.688414538Z W0621 20:58:19.687702       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Deployment ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.688421569Z W0621 20:58:19.687784       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Endpoints ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.688425676Z W0621 20:58:19.687873       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Pod ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.688429483Z W0621 20:58:19.687982       1 reflector.go:334] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: watch of <nil> ended with: very short watch: k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.689841579Z W0621 20:58:19.688258       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta2.ReplicaSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.689857080Z W0621 20:58:19.688337       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.PodSecurityPolicy ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.690503280Z W0621 20:58:19.689335       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.ReplicaSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.690519964Z W0621 20:58:19.689440       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PodTemplate ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.690528025Z W0621 20:58:19.689549       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ServiceAccount ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.690534772Z W0621 20:58:19.689639       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PersistentVolumeClaim ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.693267186Z W0621 20:58:19.691821       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1alpha1.InitializerConfiguration ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.693285700Z W0621 20:58:19.691928       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.CertificateSigningRequest ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.693294982Z W0621 20:58:19.692073       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ResourceQuota ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.693301905Z W0621 20:58:19.692923       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.HorizontalPodAutoscaler ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.693538507Z W0621 20:58:19.693062       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Node ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.693560066Z W0621 20:58:19.693151       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Namespace ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.693567831Z W0621 20:58:19.693237       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PersistentVolume ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.693574016Z W0621 20:58:19.693334       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ReplicationController ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.693580135Z W0621 20:58:19.693423       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ConfigMap ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.695001287Z W0621 20:58:19.694784       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.StorageClass ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.696424984Z W0621 20:58:19.695843       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.CronJob ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.696443659Z W0621 20:58:19.695853       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.DaemonSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.696451960Z W0621 20:58:19.695928       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta2.DaemonSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:19.696459406Z W0621 20:58:19.696359       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Deployment ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-21T20:58:20.707281108Z E0621 20:58:20.705347       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodSecurityPolicy: Get https://proxy.local:6444/apis/extensions/v1beta1/podsecuritypolicies?resourceVersion=0: EOF
2018-06-21T20:58:20.707300989Z E0621 20:58:20.705475       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Secret: Get https://proxy.local:6444/api/v1/secrets?resourceVersion=0: EOF
2018-06-21T20:58:20.707320584Z E0621 20:58:20.705573       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PersistentVolumeClaim: Get https://proxy.local:6444/api/v1/persistentvolumeclaims?resourceVersion=0: EOF
2018-06-21T20:58:20.707327319Z E0621 20:58:20.705660       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.NetworkPolicy: Get https://proxy.local:6444/apis/networking.k8s.io/v1/networkpolicies?resourceVersion=0: EOF
2018-06-21T20:58:20.707333514Z E0621 20:58:20.705741       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/compose.docker.com/v1beta1/stacks?resourceVersion=0: EOF
2018-06-21T20:58:20.707340189Z E0621 20:58:20.705823       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta2.ReplicaSet: Get https://proxy.local:6444/apis/apps/v1beta2/replicasets?resourceVersion=0: EOF
2018-06-21T20:58:20.707346350Z E0621 20:58:20.705905       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.ControllerRevision: Get https://proxy.local:6444/apis/apps/v1beta1/controllerrevisions?resourceVersion=0: EOF
2018-06-21T20:58:20.707352742Z E0621 20:58:20.706082       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.LimitRange: Get https://proxy.local:6444/api/v1/limitranges?resourceVersion=0: EOF
2018-06-21T20:58:20.707359810Z E0621 20:58:20.706168       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Service: Get https://proxy.local:6444/api/v1/services?resourceVersion=0: EOF
2018-06-21T20:58:20.707366110Z E0621 20:58:20.706249       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Ingress: Get https://proxy.local:6444/apis/extensions/v1beta1/ingresses?resourceVersion=0: EOF
2018-06-21T20:58:20.707372254Z E0621 20:58:20.706328       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Job: Get https://proxy.local:6444/apis/batch/v1/jobs?resourceVersion=0: EOF
2018-06-21T20:58:20.707378335Z E0621 20:58:20.706406       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Endpoints: Get https://proxy.local:6444/api/v1/endpoints?resourceVersion=0: EOF
2018-06-21T20:58:20.707384432Z E0621 20:58:20.706488       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Deployment: Get https://proxy.local:6444/apis/apps/v1beta1/deployments?resourceVersion=0: EOF
2018-06-21T20:58:20.707390678Z E0621 20:58:20.706561       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Pod: Get https://proxy.local:6444/api/v1/pods?resourceVersion=0: EOF
2018-06-21T20:58:20.707396669Z E0621 20:58:20.706648       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1alpha1.ExternalAdmissionHookConfiguration: Get https://proxy.local:6444/apis/admissionregistration.k8s.io/v1alpha1/externaladmissionhookconfigurations?resourceVersion=0: EOF
2018-06-21T20:58:20.707407053Z E0621 20:58:20.706704       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.StatefulSet: Get https://proxy.local:6444/apis/apps/v1beta1/statefulsets?resourceVersion=0: EOF
2018-06-21T20:58:20.707427795Z E0621 20:58:20.706814       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.ReplicaSet: Get https://proxy.local:6444/apis/extensions/v1beta1/replicasets?resourceVersion=0: EOF
2018-06-21T20:58:20.708780176Z E0621 20:58:20.707772       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Node: Get https://proxy.local:6444/api/v1/nodes?resourceVersion=0: EOF
2018-06-21T20:58:20.708792884Z E0621 20:58:20.707799       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodDisruptionBudget: Get https://proxy.local:6444/apis/policy/v1beta1/poddisruptionbudgets?resourceVersion=0: EOF
2018-06-21T20:58:20.708799667Z E0621 20:58:20.707879       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1alpha1.InitializerConfiguration: Get https://proxy.local:6444/apis/admissionregistration.k8s.io/v1alpha1/initializerconfigurations?resourceVersion=0: EOF
2018-06-21T20:58:20.708806256Z E0621 20:58:20.707897       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/extensions/v1beta1/networkpolicies?resourceVersion=0: EOF
2018-06-21T20:58:20.708812858Z E0621 20:58:20.707951       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.CertificateSigningRequest: Get https://proxy.local:6444/apis/certificates.k8s.io/v1beta1/certificatesigningrequests?resourceVersion=0: EOF
2018-06-21T20:58:20.708819285Z E0621 20:58:20.708022       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PodTemplate: Get https://proxy.local:6444/api/v1/podtemplates?resourceVersion=0: EOF
2018-06-21T20:58:20.708828369Z E0621 20:58:20.708045       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ConfigMap: Get https://proxy.local:6444/api/v1/configmaps?resourceVersion=0: EOF
2018-06-21T20:58:20.708834534Z E0621 20:58:20.708100       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ResourceQuota: Get https://proxy.local:6444/api/v1/resourcequotas?resourceVersion=0: EOF
2018-06-21T20:58:20.708841679Z E0621 20:58:20.708130       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ServiceAccount: Get https://proxy.local:6444/api/v1/serviceaccounts?resourceVersion=0: EOF
2018-06-21T20:58:20.708847977Z E0621 20:58:20.708179       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.StorageClass: Get https://proxy.local:6444/apis/storage.k8s.io/v1/storageclasses?resourceVersion=0: EOF
2018-06-21T20:58:20.708854177Z E0621 20:58:20.708204       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.DaemonSet: Get https://proxy.local:6444/apis/extensions/v1beta1/daemonsets?resourceVersion=0: EOF
2018-06-21T20:58:20.708868096Z E0621 20:58:20.708248       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Namespace: Get https://proxy.local:6444/api/v1/namespaces?resourceVersion=0: EOF
2018-06-21T20:58:20.708874541Z E0621 20:58:20.708269       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.HorizontalPodAutoscaler: Get https://proxy.local:6444/apis/autoscaling/v1/horizontalpodautoscalers?resourceVersion=0: EOF
2018-06-21T20:58:20.708880843Z E0621 20:58:20.708322       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PersistentVolume: Get https://proxy.local:6444/api/v1/persistentvolumes?resourceVersion=0: EOF
2018-06-21T20:58:20.708887008Z E0621 20:58:20.708340       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ReplicationController: Get https://proxy.local:6444/api/v1/replicationcontrollers?resourceVersion=0: EOF
2018-06-21T20:58:20.721440020Z E0621 20:58:20.721238       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.CronJob: Get https://proxy.local:6444/apis/batch/v1beta1/cronjobs?resourceVersion=0: EOF
2018-06-21T20:58:20.773440707Z E0621 20:58:20.773040       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta2.DaemonSet: Get https://proxy.local:6444/apis/apps/v1beta2/daemonsets?resourceVersion=0: EOF
2018-06-21T20:58:20.834169000Z E0621 20:58:20.829161       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Deployment: Get https://proxy.local:6444/apis/extensions/v1beta1/deployments?resourceVersion=0: EOF
2018-06-21T20:58:21.334540870Z E0621 20:58:21.334304       1 leaderelection.go:224] error retrieving resource lock kube-system/kube-controller-manager: Get https://proxy.local:6444/api/v1/namespaces/kube-system/endpoints/kube-controller-manager: EOF
2018-06-21T20:58:21.723171686Z E0621 20:58:21.712504       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PersistentVolumeClaim: Get https://proxy.local:6444/api/v1/persistentvolumeclaims?resourceVersion=0: EOF
2018-06-21T20:58:21.723195216Z E0621 20:58:21.713131       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodSecurityPolicy: Get https://proxy.local:6444/apis/extensions/v1beta1/podsecuritypolicies?resourceVersion=0: EOF
2018-06-21T20:58:21.723203586Z E0621 20:58:21.713224       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Secret: Get https://proxy.local:6444/api/v1/secrets?resourceVersion=0: EOF
2018-06-21T20:58:21.733665676Z E0621 20:58:21.723752       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.ControllerRevision: Get https://proxy.local:6444/apis/apps/v1beta1/controllerrevisions?resourceVersion=0: EOF
2018-06-21T20:58:21.733692877Z E0621 20:58:21.723859       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.NetworkPolicy: Get https://proxy.local:6444/apis/networking.k8s.io/v1/networkpolicies?resourceVersion=0: EOF
2018-06-21T20:58:21.733702445Z E0621 20:58:21.723935       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta2.ReplicaSet: Get https://proxy.local:6444/apis/apps/v1beta2/replicasets?resourceVersion=0: EOF
2018-06-21T20:58:21.733721073Z E0621 20:58:21.724027       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/compose.docker.com/v1beta1/stacks?resourceVersion=0: EOF
2018-06-21T20:58:21.736615079Z E0621 20:58:21.734217       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Service: Get https://proxy.local:6444/api/v1/services?resourceVersion=0: EOF
2018-06-21T20:58:21.736634078Z E0621 20:58:21.734325       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Endpoints: Get https://proxy.local:6444/api/v1/endpoints?resourceVersion=0: EOF
2018-06-21T20:58:21.736641897Z E0621 20:58:21.734411       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Deployment: Get https://proxy.local:6444/apis/apps/v1beta1/deployments?resourceVersion=0: EOF
2018-06-21T20:58:21.736648077Z E0621 20:58:21.734500       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.ReplicaSet: Get https://proxy.local:6444/apis/extensions/v1beta1/replicasets?resourceVersion=0: EOF
2018-06-21T20:58:21.736654418Z E0621 20:58:21.734586       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Job: Get https://proxy.local:6444/apis/batch/v1/jobs?resourceVersion=0: EOF
2018-06-21T20:58:21.736660576Z E0621 20:58:21.734665       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Ingress: Get https://proxy.local:6444/apis/extensions/v1beta1/ingresses?resourceVersion=0: EOF
2018-06-21T20:58:21.736666945Z E0621 20:58:21.734739       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Pod: Get https://proxy.local:6444/api/v1/pods?resourceVersion=0: EOF
2018-06-21T20:58:21.736673429Z E0621 20:58:21.734809       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.LimitRange: Get https://proxy.local:6444/api/v1/limitranges?resourceVersion=0: EOF
2018-06-21T20:58:21.736680386Z E0621 20:58:21.734886       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1alpha1.ExternalAdmissionHookConfiguration: Get https://proxy.local:6444/apis/admissionregistration.k8s.io/v1alpha1/externaladmissionhookconfigurations?resourceVersion=0: EOF
2018-06-21T20:58:21.738781501Z E0621 20:58:21.736678       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Node: Get https://proxy.local:6444/api/v1/nodes?resourceVersion=0: EOF
2018-06-21T20:58:21.738817795Z E0621 20:58:21.736771       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.StatefulSet: Get https://proxy.local:6444/apis/apps/v1beta1/statefulsets?resourceVersion=0: EOF
2018-06-21T20:58:21.738826113Z E0621 20:58:21.736852       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodDisruptionBudget: Get https://proxy.local:6444/apis/policy/v1beta1/poddisruptionbudgets?resourceVersion=0: EOF
2018-06-21T20:58:21.738832459Z E0621 20:58:21.736954       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/extensions/v1beta1/networkpolicies?resourceVersion=0: EOF
2018-06-21T20:58:21.772272498Z E0621 20:58:21.770908       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1alpha1.InitializerConfiguration: Get https://proxy.local:6444/apis/admissionregistration.k8s.io/v1alpha1/initializerconfigurations?resourceVersion=0: EOF
2018-06-21T20:58:21.820994826Z E0621 20:58:21.820766       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.CertificateSigningRequest: Get https://proxy.local:6444/apis/certificates.k8s.io/v1beta1/certificatesigningrequests?resourceVersion=0: EOF
2018-06-21T20:58:21.871565546Z E0621 20:58:21.871303       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PodTemplate: Get https://proxy.local:6444/api/v1/podtemplates?resourceVersion=0: EOF
2018-06-21T20:58:21.926709163Z E0621 20:58:21.926469       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ConfigMap: Get https://proxy.local:6444/api/v1/configmaps?resourceVersion=0: EOF
2018-06-21T20:58:21.975943181Z E0621 20:58:21.975684       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ResourceQuota: Get https://proxy.local:6444/api/v1/resourcequotas?resourceVersion=0: EOF
2018-06-21T20:58:22.021017590Z E0621 20:58:22.020764       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ServiceAccount: Get https://proxy.local:6444/api/v1/serviceaccounts?resourceVersion=0: EOF
2018-06-21T20:58:22.071023947Z E0621 20:58:22.070756       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.StorageClass: Get https://proxy.local:6444/apis/storage.k8s.io/v1/storageclasses?resourceVersion=0: EOF
2018-06-21T20:58:22.120965423Z E0621 20:58:22.120690       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.DaemonSet: Get https://proxy.local:6444/apis/extensions/v1beta1/daemonsets?resourceVersion=0: EOF
2018-06-21T20:58:22.170923405Z E0621 20:58:22.170707       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Namespace: Get https://proxy.local:6444/api/v1/namespaces?resourceVersion=0: EOF
2018-06-21T20:58:22.220988788Z E0621 20:58:22.220724       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.HorizontalPodAutoscaler: Get https://proxy.local:6444/apis/autoscaling/v1/horizontalpodautoscalers?resourceVersion=0: EOF
2018-06-21T20:58:22.271282257Z E0621 20:58:22.271008       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PersistentVolume: Get https://proxy.local:6444/api/v1/persistentvolumes?resourceVersion=0: EOF
2018-06-21T20:58:22.321359604Z E0621 20:58:22.320899       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ReplicationController: Get https://proxy.local:6444/api/v1/replicationcontrollers?resourceVersion=0: EOF
2018-06-21T20:58:22.370782335Z E0621 20:58:22.370655       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.CronJob: Get https://proxy.local:6444/apis/batch/v1beta1/cronjobs?resourceVersion=0: EOF
2018-06-21T20:58:22.420994140Z E0621 20:58:22.420764       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta2.DaemonSet: Get https://proxy.local:6444/apis/apps/v1beta2/daemonsets?resourceVersion=0: EOF
2018-06-21T20:58:22.471531127Z E0621 20:58:22.471292       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Deployment: Get https://proxy.local:6444/apis/extensions/v1beta1/deployments?resourceVersion=0: EOF
2018-06-21T20:58:22.714589920Z E0621 20:58:22.713854       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PersistentVolumeClaim: Get https://proxy.local:6444/api/v1/persistentvolumeclaims?resourceVersion=0: EOF
2018-06-21T20:58:22.716260568Z E0621 20:58:22.715997       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodSecurityPolicy: Get https://proxy.local:6444/apis/extensions/v1beta1/podsecuritypolicies?resourceVersion=0: EOF
2018-06-21T20:58:22.717314584Z E0621 20:58:22.716881       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Secret: Get https://proxy.local:6444/api/v1/secrets?resourceVersion=0: EOF
2018-06-21T20:58:22.725395920Z E0621 20:58:22.725137       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.ControllerRevision: Get https://proxy.local:6444/apis/apps/v1beta1/controllerrevisions?resourceVersion=0: EOF
2018-06-21T20:58:22.726570922Z E0621 20:58:22.726331       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.NetworkPolicy: Get https://proxy.local:6444/apis/networking.k8s.io/v1/networkpolicies?resourceVersion=0: EOF
2018-06-21T20:58:22.729137560Z E0621 20:58:22.728883       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/compose.docker.com/v1beta1/stacks?resourceVersion=0: EOF
2018-06-21T20:58:22.749816544Z E0621 20:58:22.749656       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/extensions/v1beta1/networkpolicies?resourceVersion=0: EOF
2018-06-21T20:58:22.771286236Z E0621 20:58:22.770999       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta2.ReplicaSet: Get https://proxy.local:6444/apis/apps/v1beta2/replicasets?resourceVersion=0: EOF
2018-06-21T20:58:22.821238961Z E0621 20:58:22.820983       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Service: Get https://proxy.local:6444/api/v1/services?resourceVersion=0: EOF
2018-06-21T20:58:22.870824894Z E0621 20:58:22.870760       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Endpoints: Get https://proxy.local:6444/api/v1/endpoints?resourceVersion=0: EOF
2018-06-21T20:58:22.921152127Z E0621 20:58:22.920854       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Deployment: Get https://proxy.local:6444/apis/apps/v1beta1/deployments?resourceVersion=0: EOF
2018-06-21T20:58:22.972487804Z E0621 20:58:22.972183       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.ReplicaSet: Get https://proxy.local:6444/apis/extensions/v1beta1/replicasets?resourceVersion=0: EOF
2018-06-21T20:58:23.021414992Z E0621 20:58:23.021199       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Job: Get https://proxy.local:6444/apis/batch/v1/jobs?resourceVersion=0: EOF
2018-06-21T20:58:23.074497208Z E0621 20:58:23.074155       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Ingress: Get https://proxy.local:6444/apis/extensions/v1beta1/ingresses?resourceVersion=0: EOF
2018-06-21T20:58:23.121241213Z E0621 20:58:23.120955       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Pod: Get https://proxy.local:6444/api/v1/pods?resourceVersion=0: EOF
2018-06-21T20:58:23.170926535Z E0621 20:58:23.170676       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.LimitRange: Get https://proxy.local:6444/api/v1/limitranges?resourceVersion=0: EOF
2018-06-21T20:58:23.220990295Z E0621 20:58:23.220779       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1alpha1.ExternalAdmissionHookConfiguration: Get https://proxy.local:6444/apis/admissionregistration.k8s.io/v1alpha1/externaladmissionhookconfigurations?resourceVersion=0: EOF
2018-06-21T20:58:23.270981385Z E0621 20:58:23.270841       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Node: Get https://proxy.local:6444/api/v1/nodes?resourceVersion=0: EOF
2018-06-21T20:58:23.321155487Z E0621 20:58:23.320863       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.StatefulSet: Get https://proxy.local:6444/apis/apps/v1beta1/statefulsets?resourceVersion=0: EOF
2018-06-21T20:58:23.330722766Z E0621 20:58:23.330503       1 leaderelection.go:224] error retrieving resource lock kube-system/kube-controller-manager: Get https://proxy.local:6444/api/v1/namespaces/kube-system/endpoints/kube-controller-manager: EOF
2018-06-21T20:58:23.371696580Z E0621 20:58:23.371486       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodDisruptionBudget: Get https://proxy.local:6444/apis/policy/v1beta1/poddisruptionbudgets?resourceVersion=0: EOF
2018-06-21T20:58:23.420956023Z E0621 20:58:23.420794       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1alpha1.InitializerConfiguration: Get https://proxy.local:6444/apis/admissionregistration.k8s.io/v1alpha1/initializerconfigurations?resourceVersion=0: EOF
2018-06-21T20:58:23.470989935Z E0621 20:58:23.470755       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.CertificateSigningRequest: Get https://proxy.local:6444/apis/certificates.k8s.io/v1beta1/certificatesigningrequests?resourceVersion=0: EOF
2018-06-21T20:58:23.520983536Z E0621 20:58:23.520793       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PodTemplate: Get https://proxy.local:6444/api/v1/podtemplates?resourceVersion=0: EOF
2018-06-21T20:58:23.578848306Z E0621 20:58:23.578563       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ConfigMap: Get https://proxy.local:6444/api/v1/configmaps?resourceVersion=0: EOF
2018-06-21T20:58:23.621431622Z E0621 20:58:23.621132       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ResourceQuota: Get https://proxy.local:6444/api/v1/resourcequotas?resourceVersion=0: EOF
2018-06-21T20:58:23.670974602Z E0621 20:58:23.670783       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ServiceAccount: Get https://proxy.local:6444/api/v1/serviceaccounts?resourceVersion=0: EOF
2018-06-21T20:58:23.723036888Z E0621 20:58:23.722414       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.StorageClass: Get https://proxy.local:6444/apis/storage.k8s.io/v1/storageclasses?resourceVersion=0: EOF
2018-06-21T20:58:23.732849897Z E0621 20:58:23.732559       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/compose.docker.com/v1beta1/stacks?resourceVersion=0: EOF
2018-06-21T20:58:23.751245586Z E0621 20:58:23.750992       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/extensions/v1beta1/networkpolicies?resourceVersion=0: EOF
2018-06-21T20:58:23.770862017Z E0621 20:58:23.770680       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.DaemonSet: Get https://proxy.local:6444/apis/extensions/v1beta1/daemonsets?resourceVersion=0: EOF
2018-06-21T20:58:23.821591495Z E0621 20:58:23.821217       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Namespace: Get https://proxy.local:6444/api/v1/namespaces?resourceVersion=0: EOF
2018-06-21T20:58:23.872399348Z E0621 20:58:23.872221       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.HorizontalPodAutoscaler: Get https://proxy.local:6444/apis/autoscaling/v1/horizontalpodautoscalers?resourceVersion=0: EOF
2018-06-21T20:58:23.921227284Z E0621 20:58:23.921107       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PersistentVolume: Get https://proxy.local:6444/api/v1/persistentvolumes?resourceVersion=0: EOF
2018-06-21T20:58:23.971981382Z E0621 20:58:23.971744       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ReplicationController: Get https://proxy.local:6444/api/v1/replicationcontrollers?resourceVersion=0: EOF
2018-06-21T20:58:24.021211312Z E0621 20:58:24.020957       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.CronJob: Get https://proxy.local:6444/apis/batch/v1beta1/cronjobs?resourceVersion=0: EOF
2018-06-21T20:58:24.071036578Z E0621 20:58:24.070867       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta2.DaemonSet: Get https://proxy.local:6444/apis/apps/v1beta2/daemonsets?resourceVersion=0: EOF
2018-06-21T20:58:24.121130972Z E0621 20:58:24.120937       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Deployment: Get https://proxy.local:6444/apis/extensions/v1beta1/deployments?resourceVersion=0: EOF
2018-06-21T20:58:24.170949491Z E0621 20:58:24.170753       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PersistentVolumeClaim: Get https://proxy.local:6444/api/v1/persistentvolumeclaims?resourceVersion=0: EOF
2018-06-21T20:58:24.222409448Z E0621 20:58:24.222154       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodSecurityPolicy: Get https://proxy.local:6444/apis/extensions/v1beta1/podsecuritypolicies?resourceVersion=0: EOF
2018-06-21T20:58:24.271477410Z E0621 20:58:24.271242       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Secret: Get https://proxy.local:6444/api/v1/secrets?resourceVersion=0: EOF
2018-06-21T20:58:24.314966532Z E0621 20:58:24.305148       1 cronjob_controller.go:113] can't list Jobs: Get https://proxy.local:6444/apis/batch/v1/jobs: EOF
2018-06-21T20:58:24.326995087Z E0621 20:58:24.326371       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.ControllerRevision: Get https://proxy.local:6444/apis/apps/v1beta1/controllerrevisions?resourceVersion=0: EOF
2018-06-21T20:58:24.371137621Z E0621 20:58:24.370868       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.NetworkPolicy: Get https://proxy.local:6444/apis/networking.k8s.io/v1/networkpolicies?resourceVersion=0: EOF
2018-06-21T20:58:30.146534129Z I0621 20:58:30.146181       1 event.go:218] Event(v1.ObjectReference{Kind:"DaemonSet", Namespace:"kube-system", Name:"calico-node", UID:"1f830495-7590-11e8-8955-0242ac110012", APIVersion:"extensions", ResourceVersion:"3845", FieldPath:""}): type: 'Normal' reason: 'SuccessfulDelete' Deleted pod: calico-node-thtt7
2018-06-21T20:58:30.171517831Z I0621 20:58:30.171232       1 event.go:218] Event(v1.ObjectReference{Kind:"DaemonSet", Namespace:"kube-system", Name:"calico-node", UID:"1f830495-7590-11e8-8955-0242ac110012", APIVersion:"extensions", ResourceVersion:"3850", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: calico-node-xj54s
2018-06-21T20:58:30.198817211Z E0621 20:58:30.195302       1 daemon_controller.go:263] kube-system/calico-node failed with : error storing status for daemon set &v1beta1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"calico-node", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/extensions/v1beta1/namespaces/kube-system/daemonsets/calico-node", UID:"1f830495-7590-11e8-8955-0242ac110012", ResourceVersion:"3850", Generation:2, CreationTimestamp:v1.Time{Time:time.Time{sec:63665209049, nsec:0, loc:(*time.Location)(0x9e5a580)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"calico-node"}, Annotations:map[string]string{"kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"extensions/v1beta1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"k8s-app\":\"calico-node\"},\"name\":\"calico-node\",\"namespace\":\"kube-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"k8s-app\":\"calico-node\"}},\"template\":{\"metadata\":{\"annotations\":{\"scheduler.alpha.kubernetes.io/critical-pod\":\"\"},\"labels\":{\"k8s-app\":\"calico-node\"}},\"spec\":{\"containers\":[{\"env\":[{\"name\":\"ETCD_ENDPOINTS\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"etcd_endpoints\",\"name\":\"calico-config\"}}},{\"name\":\"CALICO_NETWORKING_BACKEND\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"calico_backend\",\"name\":\"calico-config\"}}},{\"name\":\"CLUSTER_TYPE\",\"value\":\"k8s,bgp\"},{\"name\":\"CALICO_DISABLE_FILE_LOGGING\",\"value\":\"true\"},{\"name\":\"CALICO_IPV4POOL_IPIP\",\"value\":\"always\"},{\"name\":\"FELIX_IPINIPENABLED\",\"value\":\"true\"},{\"name\":\"FELIX_DEFAULTENDPOINTTOHOSTACTION\",\"value\":\"ACCEPT\"},{\"name\":\"CALICO_IPV4POOL_CIDR\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"calico_pool\",\"name\":\"calico-config\"}}},{\"name\":\"CALICO_K8S_NODE_REF\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"spec.nodeName\"}}},{\"name\":\"FELIX_IPV6SUPPORT\",\"value\":\"false\"},{\"name\":\"FELIX_LOGSEVERITYSCREEN\",\"value\":\"info\"},{\"name\":\"FELIX_IPINIPMTU\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"felix_ipinipmtu\",\"name\":\"calico-config\"}}},{\"name\":\"ETCD_CA_CERT_FILE\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"etcd_ca\",\"name\":\"calico-config\"}}},{\"name\":\"ETCD_KEY_FILE\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"etcd_key\",\"name\":\"calico-config\"}}},{\"name\":\"ETCD_CERT_FILE\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"etcd_cert\",\"name\":\"calico-config\"}}},{\"name\":\"NODENAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"spec.nodeName\"}}},{\"name\":\"IP\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"status.hostIP\"}}},{\"name\":\"FELIX_HEALTHENABLED\",\"value\":\"true\"}],\"image\":\"docker/ucp-calico-node:3.0.2\",\"livenessProbe\":{\"failureThreshold\":6,\"httpGet\":{\"path\":\"/liveness\",\"port\":9099},\"initialDelaySeconds\":10,\"periodSeconds\":10},\"name\":\"calico-node\",\"readinessProbe\":{\"httpGet\":{\"path\":\"/readiness\",\"port\":9099},\"periodSeconds\":10},\"resources\":{\"requests\":{\"cpu\":\"250m\"}},\"securityContext\":{\"privileged\":true},\"volumeMounts\":[{\"mountPath\":\"/lib/modules\",\"name\":\"lib-modules\",\"readOnly\":true},{\"mountPath\":\"/var/run/calico\",\"name\":\"var-run-calico\",\"readOnly\":false},{\"mountPath\":\"/calico-secrets\",\"name\":\"etcd-certs\"}]},{\"command\":[\"/install-cni.sh\"],\"env\":[{\"name\":\"CNI_CONF_NAME\",\"value\":\"10-calico.conflist\"},{\"name\":\"ETCD_ENDPOINTS\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"etcd_endpoints\",\"name\":\"calico-config\"}}},{\"name\":\"CNI_NETWORK_CONFIG\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"cni_network_config\",\"name\":\"calico-config\"}}}],\"image\":\"docker/ucp-calico-cni:3.0.2\",\"name\":\"install-cni\",\"securityContext\":{\"privileged\":true},\"volumeMounts\":[{\"mountPath\":\"/host/opt/cni/bin\",\"name\":\"cni-bin-dir\"},{\"mountPath\":\"/host/etc/cni/net.d\",\"name\":\"cni-net-dir\"},{\"mountPath\":\"/calico-secrets\",\"name\":\"etcd-certs\"}]}],\"hostNetwork\":true,\"serviceAccountName\":\"cni-plugin\",\"terminationGracePeriodSeconds\":0,\"tolerations\":[{\"effect\":\"NoSchedule\",\"key\":\"node.cloudprovider.kubernetes.io/uninitialized\",\"value\":\"true\"},{\"effect\":\"NoSchedule\",\"key\":\"node-role.kubernetes.io/master\"},{\"key\":\"CriticalAddonsOnly\",\"operator\":\"Exists\"}],\"volumes\":[{\"hostPath\":{\"path\":\"/lib/modules\"},\"name\":\"lib-modules\"},{\"hostPath\":{\"path\":\"/var/run/calico\"},\"name\":\"var-run-calico\"},{\"hostPath\":{\"path\":\"/opt/cni/bin\"},\"name\":\"cni-bin-dir\"},{\"hostPath\":{\"path\":\"/etc/cni/net.d\"},\"name\":\"cni-net-dir\"},{\"name\":\"etcd-certs\",\"secret\":{\"secretName\":\"calico-etcd-secrets\"}}]}},\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1beta1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc422940860), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{sec:0, nsec:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"calico-node"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":""}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"lib-modules", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc422940880), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}, v1.Volume{Name:"var-run-calico", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc4229408a0), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}, v1.Volume{Name:"cni-bin-dir", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc4229408c0), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}, v1.Volume{Name:"cni-net-dir", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc4229408e0), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}, v1.Volume{Name:"etcd-certs", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc42293c9c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"calico-node", Image:"docker/ucp-calico-node:3.0.2", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"ETCD_ENDPOINTS", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc422940940)}, v1.EnvVar{Name:"CALICO_NETWORKING_BACKEND", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc422940980)}, v1.EnvVar{Name:"CLUSTER_TYPE", Value:"k8s,bgp", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"CALICO_DISABLE_FILE_LOGGING", Value:"true", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"CALICO_IPV4POOL_IPIP", Value:"always", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"FELIX_IPINIPENABLED", Value:"true", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"FELIX_DEFAULTENDPOINTTOHOSTACTION", Value:"ACCEPT", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"CALICO_IPV4POOL_CIDR", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc422940a20)}, v1.EnvVar{Name:"CALICO_K8S_NODE_REF", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc422940a60)}, v1.EnvVar{Name:"FELIX_IPV6SUPPORT", Value:"false", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"FELIX_LOGSEVERITYSCREEN", Value:"info", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"FELIX_IPINIPMTU", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc422940ae0)}, v1.EnvVar{Name:"ETCD_CA_CERT_FILE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc422940b20)}, v1.EnvVar{Name:"ETCD_KEY_FILE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc422940b40)}, v1.EnvVar{Name:"ETCD_CERT_FILE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc422940b60)}, v1.EnvVar{Name:"NODENAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc422940b80)}, v1.EnvVar{Name:"IP", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc422940bc0)}, v1.EnvVar{Name:"FELIX_HEALTHENABLED", Value:"true", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:250, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"250m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"lib-modules", ReadOnly:true, MountPath:"/lib/modules", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}, v1.VolumeMount{Name:"var-run-calico", ReadOnly:false, MountPath:"/var/run/calico", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}, v1.VolumeMount{Name:"etcd-certs", ReadOnly:false, MountPath:"/calico-secrets", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, LivenessProbe:(*v1.Probe)(0xc422942f60), ReadinessProbe:(*v1.Probe)(0xc422942f90), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc42293ca40), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"install-cni", Image:"docker/ucp-calico-cni:3.0.2", Command:[]string{"/install-cni.sh"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"CNI_CONF_NAME", Value:"10-calico.conflist", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"ETCD_ENDPOINTS", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc422940c80)}, v1.EnvVar{Name:"CNI_NETWORK_CONFIG", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc422940cc0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"cni-bin-dir", ReadOnly:false, MountPath:"/host/opt/cni/bin", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}, v1.VolumeMount{Name:"cni-net-dir", ReadOnly:false, MountPath:"/host/etc/cni/net.d", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}, v1.VolumeMount{Name:"etcd-certs", ReadOnly:false, MountPath:"/calico-secrets", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc42293cac0), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4227d7c08), Act2018-06-21T20:58:30.199055086Z iveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"cni-plugin", DeprecatedServiceAccount:"cni-plugin", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, SecurityContext:(*v1.PodSecurityContext)(0xc42293cb00), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.cloudprovider.kubernetes.io/uninitialized", Operator:"", Value:"true", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node-role.kubernetes.io/master", Operator:"", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"com.docker.ucp.orchestrator.kubernetes", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"com.docker.ucp.manager", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil)}}, UpdateStrategy:v1beta1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1beta1.RollingUpdateDaemonSet)(0xc420103590)}, MinReadySeconds:0, TemplateGeneration:2, RevisionHistoryLimit:(*int32)(0xc4227d7c6c)}, Status:v1beta1.DaemonSetStatus{CurrentNumberScheduled:3, NumberMisscheduled:0, DesiredNumberScheduled:4, NumberReady:3, ObservedGeneration:2, UpdatedNumberScheduled:0, NumberAvailable:3, NumberUnavailable:1, CollisionCount:(*int32)(nil)}}: Operation cannot be fulfilled on daemonsets.extensions "calico-node": the object has been modified; please apply your changes to the latest version and try again
2018-06-21T20:58:30.240383747Z I0621 20:58:30.239506       1 event.go:218] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"calico-kube-controllers", UID:"1f90a604-7590-11e8-8955-0242ac110012", APIVersion:"extensions", ResourceVersion:"3854", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled down replica set calico-kube-controllers-64ffdc6dbf to 0
2018-06-21T20:58:30.269423811Z I0621 20:58:30.268111       1 event.go:218] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"calico-kube-controllers-64ffdc6dbf", UID:"1f917f9c-7590-11e8-8955-0242ac110012", APIVersion:"extensions", ResourceVersion:"3855", FieldPath:""}): type: 'Normal' reason: 'SuccessfulDelete' Deleted pod: calico-kube-controllers-64ffdc6dbf-kmqgw
2018-06-21T20:58:31.617219613Z I0621 20:58:31.616912       1 event.go:218] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"compose", UID:"25051e35-7590-11e8-8955-0242ac110012", APIVersion:"extensions", ResourceVersion:"3867", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set compose-6df8746695 to 1
2018-06-21T20:58:31.624756093Z I0621 20:58:31.624460       1 event.go:218] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"compose-6df8746695", UID:"dacb5a5c-7595-11e8-b33c-0242ac110005", APIVersion:"extensions", ResourceVersion:"3868", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: compose-6df8746695-d6q2m
2018-06-21T20:58:31.631956160Z I0621 20:58:31.631647       1 event.go:218] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"compose", UID:"25051e35-7590-11e8-8955-0242ac110012", APIVersion:"extensions", ResourceVersion:"3867", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled down replica set compose-76b854f656 to 0
2018-06-21T20:58:31.651345151Z I0621 20:58:31.650878       1 event.go:218] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"compose-76b854f656", UID:"2505c815-7590-11e8-8955-0242ac110012", APIVersion:"extensions", ResourceVersion:"3872", FieldPath:""}): type: 'Normal' reason: 'SuccessfulDelete' Deleted pod: compose-76b854f656-rfqjd
2018-06-21T20:58:33.052249932Z I0621 20:58:33.048615       1 event.go:218] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"kube-dns", UID:"25afbc4a-7590-11e8-8955-0242ac110012", APIVersion:"extensions", ResourceVersion:"3896", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set kube-dns-fbf6ff8fb to 1
2018-06-21T20:58:33.058739474Z I0621 20:58:33.058526       1 event.go:218] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kube-dns-fbf6ff8fb", UID:"dba5b81c-7595-11e8-b33c-0242ac110005", APIVersion:"extensions", ResourceVersion:"3897", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: kube-dns-fbf6ff8fb-w5zw8
2018-06-21T20:58:40.465432578Z I0621 20:58:40.464766       1 event.go:218] Event(v1.ObjectReference{Kind:"DaemonSet", Namespace:"kube-system", Name:"calico-node", UID:"1f830495-7590-11e8-8955-0242ac110012", APIVersion:"extensions", ResourceVersion:"3852", FieldPath:""}): type: 'Normal' reason: 'SuccessfulDelete' Deleted pod: calico-node-kr476
2018-06-21T20:58:40.485662630Z I0621 20:58:40.485287       1 event.go:218] Event(v1.ObjectReference{Kind:"DaemonSet", Namespace:"kube-system", Name:"calico-node", UID:"1f830495-7590-11e8-8955-0242ac110012", APIVersion:"extensions", ResourceVersion:"3951", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: calico-node-v74wg
2018-06-21T20:58:42.719845668Z I0621 20:58:42.719497       1 event.go:218] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"calico-kube-controllers", UID:"1f90a604-7590-11e8-8955-0242ac110012", APIVersion:"extensions", ResourceVersion:"3862", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set calico-kube-controllers-54f4d75698 to 1
2018-06-21T20:58:42.729983101Z I0621 20:58:42.729653       1 event.go:218] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"calico-kube-controllers-54f4d75698", UID:"e1691587-7595-11e8-b33c-0242ac110005", APIVersion:"extensions", ResourceVersion:"3999", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: calico-kube-controllers-54f4d75698-mxpdh
2018-06-21T20:58:45.361993130Z I0621 20:58:45.361434       1 event.go:218] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"kube-dns", UID:"25afbc4a-7590-11e8-8955-0242ac110012", APIVersion:"extensions", ResourceVersion:"3908", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled down replica set kube-dns-6d48bc9b79 to 0
2018-06-21T20:58:45.378214616Z I0621 20:58:45.377885       1 event.go:218] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kube-dns-6d48bc9b79", UID:"25b09d81-7590-11e8-8955-0242ac110012", APIVersion:"extensions", ResourceVersion:"4044", FieldPath:""}): type: 'Normal' reason: 'SuccessfulDelete' Deleted pod: kube-dns-6d48bc9b79-tvnvk
2018-06-21T20:58:46.081215737Z I0621 20:58:46.080712       1 event.go:218] Event(v1.ObjectReference{Kind:"DaemonSet", Namespace:"kube-system", Name:"calico-node", UID:"1f830495-7590-11e8-8955-0242ac110012", APIVersion:"extensions", ResourceVersion:"3954", FieldPath:""}): type: 'Normal' reason: 'SuccessfulDelete' Deleted pod: calico-node-9sw4l
2018-06-21T20:58:46.093855913Z I0621 20:58:46.093588       1 event.go:218] Event(v1.ObjectReference{Kind:"DaemonSet", Namespace:"kube-system", Name:"calico-node", UID:"1f830495-7590-11e8-8955-0242ac110012", APIVersion:"extensions", ResourceVersion:"4063", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: calico-node-qqn9t
2018-06-21T20:59:01.951634517Z I0621 20:59:01.950781       1 event.go:218] Event(v1.ObjectReference{Kind:"DaemonSet", Namespace:"kube-system", Name:"calico-node", UID:"1f830495-7590-11e8-8955-0242ac110012", APIVersion:"extensions", ResourceVersion:"4068", FieldPath:""}): type: 'Normal' reason: 'SuccessfulDelete' Deleted pod: calico-node-r6599
2018-06-21T20:59:01.968950774Z I0621 20:59:01.967649       1 event.go:218] Event(v1.ObjectReference{Kind:"DaemonSet", Namespace:"kube-system", Name:"calico-node", UID:"1f830495-7590-11e8-8955-0242ac110012", APIVersion:"extensions", ResourceVersion:"4114", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: calico-node-ftttl
2018-06-21T20:59:01.983326375Z E0621 20:59:01.983042       1 daemon_controller.go:263] kube-system/calico-node failed with : error storing status for daemon set &v1beta1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"calico-node", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/extensions/v1beta1/namespaces/kube-system/daemonsets/calico-node", UID:"1f830495-7590-11e8-8955-0242ac110012", ResourceVersion:"4114", Generation:2, CreationTimestamp:v1.Time{Time:time.Time{sec:63665209049, nsec:0, loc:(*time.Location)(0x9e5a580)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"calico-node"}, Annotations:map[string]string{"kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"extensions/v1beta1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"k8s-app\":\"calico-node\"},\"name\":\"calico-node\",\"namespace\":\"kube-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"k8s-app\":\"calico-node\"}},\"template\":{\"metadata\":{\"annotations\":{\"scheduler.alpha.kubernetes.io/critical-pod\":\"\"},\"labels\":{\"k8s-app\":\"calico-node\"}},\"spec\":{\"containers\":[{\"env\":[{\"name\":\"ETCD_ENDPOINTS\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"etcd_endpoints\",\"name\":\"calico-config\"}}},{\"name\":\"CALICO_NETWORKING_BACKEND\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"calico_backend\",\"name\":\"calico-config\"}}},{\"name\":\"CLUSTER_TYPE\",\"value\":\"k8s,bgp\"},{\"name\":\"CALICO_DISABLE_FILE_LOGGING\",\"value\":\"true\"},{\"name\":\"CALICO_IPV4POOL_IPIP\",\"value\":\"always\"},{\"name\":\"FELIX_IPINIPENABLED\",\"value\":\"true\"},{\"name\":\"FELIX_DEFAULTENDPOINTTOHOSTACTION\",\"value\":\"ACCEPT\"},{\"name\":\"CALICO_IPV4POOL_CIDR\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"calico_pool\",\"name\":\"calico-config\"}}},{\"name\":\"CALICO_K8S_NODE_REF\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"spec.nodeName\"}}},{\"name\":\"FELIX_IPV6SUPPORT\",\"value\":\"false\"},{\"name\":\"FELIX_LOGSEVERITYSCREEN\",\"value\":\"info\"},{\"name\":\"FELIX_IPINIPMTU\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"felix_ipinipmtu\",\"name\":\"calico-config\"}}},{\"name\":\"ETCD_CA_CERT_FILE\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"etcd_ca\",\"name\":\"calico-config\"}}},{\"name\":\"ETCD_KEY_FILE\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"etcd_key\",\"name\":\"calico-config\"}}},{\"name\":\"ETCD_CERT_FILE\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"etcd_cert\",\"name\":\"calico-config\"}}},{\"name\":\"NODENAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"spec.nodeName\"}}},{\"name\":\"IP\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"status.hostIP\"}}},{\"name\":\"FELIX_HEALTHENABLED\",\"value\":\"true\"}],\"image\":\"docker/ucp-calico-node:3.0.2\",\"livenessProbe\":{\"failureThreshold\":6,\"httpGet\":{\"path\":\"/liveness\",\"port\":9099},\"initialDelaySeconds\":10,\"periodSeconds\":10},\"name\":\"calico-node\",\"readinessProbe\":{\"httpGet\":{\"path\":\"/readiness\",\"port\":9099},\"periodSeconds\":10},\"resources\":{\"requests\":{\"cpu\":\"250m\"}},\"securityContext\":{\"privileged\":true},\"volumeMounts\":[{\"mountPath\":\"/lib/modules\",\"name\":\"lib-modules\",\"readOnly\":true},{\"mountPath\":\"/var/run/calico\",\"name\":\"var-run-calico\",\"readOnly\":false},{\"mountPath\":\"/calico-secrets\",\"name\":\"etcd-certs\"}]},{\"command\":[\"/install-cni.sh\"],\"env\":[{\"name\":\"CNI_CONF_NAME\",\"value\":\"10-calico.conflist\"},{\"name\":\"ETCD_ENDPOINTS\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"etcd_endpoints\",\"name\":\"calico-config\"}}},{\"name\":\"CNI_NETWORK_CONFIG\",\"valueFrom\":{\"configMapKeyRef\":{\"key\":\"cni_network_config\",\"name\":\"calico-config\"}}}],\"image\":\"docker/ucp-calico-cni:3.0.2\",\"name\":\"install-cni\",\"securityContext\":{\"privileged\":true},\"volumeMounts\":[{\"mountPath\":\"/host/opt/cni/bin\",\"name\":\"cni-bin-dir\"},{\"mountPath\":\"/host/etc/cni/net.d\",\"name\":\"cni-net-dir\"},{\"mountPath\":\"/calico-secrets\",\"name\":\"etcd-certs\"}]}],\"hostNetwork\":true,\"serviceAccountName\":\"cni-plugin\",\"terminationGracePeriodSeconds\":0,\"tolerations\":[{\"effect\":\"NoSchedule\",\"key\":\"node.cloudprovider.kubernetes.io/uninitialized\",\"value\":\"true\"},{\"effect\":\"NoSchedule\",\"key\":\"node-role.kubernetes.io/master\"},{\"key\":\"CriticalAddonsOnly\",\"operator\":\"Exists\"}],\"volumes\":[{\"hostPath\":{\"path\":\"/lib/modules\"},\"name\":\"lib-modules\"},{\"hostPath\":{\"path\":\"/var/run/calico\"},\"name\":\"var-run-calico\"},{\"hostPath\":{\"path\":\"/opt/cni/bin\"},\"name\":\"cni-bin-dir\"},{\"hostPath\":{\"path\":\"/etc/cni/net.d\"},\"name\":\"cni-net-dir\"},{\"name\":\"etcd-certs\",\"secret\":{\"secretName\":\"calico-etcd-secrets\"}}]}},\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1beta1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc4226e5ca0), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{sec:0, nsec:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"calico-node"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":""}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"lib-modules", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc4226e5cc0), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}, v1.Volume{Name:"var-run-calico", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc4226e5ce0), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}, v1.Volume{Name:"cni-bin-dir", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc4226e5d00), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}, v1.Volume{Name:"cni-net-dir", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc4226e5d20), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}, v1.Volume{Name:"etcd-certs", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc422bbca00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"calico-node", Image:"docker/ucp-calico-node:3.0.2", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"ETCD_ENDPOINTS", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc4226e5d80)}, v1.EnvVar{Name:"CALICO_NETWORKING_BACKEND", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc4226e5dc0)}, v1.EnvVar{Name:"CLUSTER_TYPE", Value:"k8s,bgp", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"CALICO_DISABLE_FILE_LOGGING", Value:"true", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"CALICO_IPV4POOL_IPIP", Value:"always", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"FELIX_IPINIPENABLED", Value:"true", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"FELIX_DEFAULTENDPOINTTOHOSTACTION", Value:"ACCEPT", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"CALICO_IPV4POOL_CIDR", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc4226e5e60)}, v1.EnvVar{Name:"CALICO_K8S_NODE_REF", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc4226e5ea0)}, v1.EnvVar{Name:"FELIX_IPV6SUPPORT", Value:"false", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"FELIX_LOGSEVERITYSCREEN", Value:"info", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"FELIX_IPINIPMTU", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc4226e5f20)}, v1.EnvVar{Name:"ETCD_CA_CERT_FILE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc4226e5f60)}, v1.EnvVar{Name:"ETCD_KEY_FILE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc4226e5f80)}, v1.EnvVar{Name:"ETCD_CERT_FILE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc4226e5fa0)}, v1.EnvVar{Name:"NODENAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc4226e5fc0)}, v1.EnvVar{Name:"IP", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc4227c4000)}, v1.EnvVar{Name:"FELIX_HEALTHENABLED", Value:"true", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:250, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"250m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"lib-modules", ReadOnly:true, MountPath:"/lib/modules", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}, v1.VolumeMount{Name:"var-run-calico", ReadOnly:false, MountPath:"/var/run/calico", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}, v1.VolumeMount{Name:"etcd-certs", ReadOnly:false, MountPath:"/calico-secrets", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, LivenessProbe:(*v1.Probe)(0xc422c7e420), ReadinessProbe:(*v1.Probe)(0xc422c7e450), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc422bbca80), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"install-cni", Image:"docker/ucp-calico-cni:3.0.2", Command:[]string{"/install-cni.sh"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"CNI_CONF_NAME", Value:"10-calico.conflist", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"ETCD_ENDPOINTS", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc4227c40c0)}, v1.EnvVar{Name:"CNI_NETWORK_CONFIG", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc4227c4100)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"cni-bin-dir", ReadOnly:false, MountPath:"/host/opt/cni/bin", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}, v1.VolumeMount{Name:"cni-net-dir", ReadOnly:false, MountPath:"/host/etc/cni/net.d", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}, v1.VolumeMount{Name:"etcd-certs", ReadOnly:false, MountPath:"/calico-secrets", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc422bbcb00), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc422f68308), Act2018-06-21T20:59:01.983448640Z iveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"cni-plugin", DeprecatedServiceAccount:"cni-plugin", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, SecurityContext:(*v1.PodSecurityContext)(0xc422bbcb40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.cloudprovider.kubernetes.io/uninitialized", Operator:"", Value:"true", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node-role.kubernetes.io/master", Operator:"", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"com.docker.ucp.orchestrator.kubernetes", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"com.docker.ucp.manager", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil)}}, UpdateStrategy:v1beta1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1beta1.RollingUpdateDaemonSet)(0xc420c48a48)}, MinReadySeconds:0, TemplateGeneration:2, RevisionHistoryLimit:(*int32)(0xc422f6836c)}, Status:v1beta1.DaemonSetStatus{CurrentNumberScheduled:4, NumberMisscheduled:0, DesiredNumberScheduled:4, NumberReady:4, ObservedGeneration:2, UpdatedNumberScheduled:3, NumberAvailable:4, NumberUnavailable:0, CollisionCount:(*int32)(nil)}}: Operation cannot be fulfilled on daemonsets.extensions "calico-node": the object has been modified; please apply your changes to the latest version and try again
2018-06-22T15:25:42.068997883Z W0622 15:25:42.065161       1 reflector.go:334] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: watch of <nil> ended with: very short watch: k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069022546Z W0622 15:25:42.065313       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Deployment ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069032546Z W0622 15:25:42.065478       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.ReplicaSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069039713Z W0622 15:25:42.065625       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.LimitRange ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069046420Z W0622 15:25:42.065765       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta2.ReplicaSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069053095Z W0622 15:25:42.065907       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Deployment ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069061308Z W0622 15:25:42.066071       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1alpha1.InitializerConfiguration ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069068537Z W0622 15:25:42.066367       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ConfigMap ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069074884Z W0622 15:25:42.066439       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Secret ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069081137Z W0622 15:25:42.066502       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.StatefulSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069098886Z W0622 15:25:42.066563       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PodTemplate ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069107015Z W0622 15:25:42.066628       1 reflector.go:334] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: watch of <nil> ended with: very short watch: k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069114698Z W0622 15:25:42.066692       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.CertificateSigningRequest ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069121225Z W0622 15:25:42.066845       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Service ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069127178Z W0622 15:25:42.067010       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta2.DaemonSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069149950Z W0622 15:25:42.067161       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.PodDisruptionBudget ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069156894Z W0622 15:25:42.067301       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PersistentVolumeClaim ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069162894Z W0622 15:25:42.067439       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PersistentVolume ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069168936Z W0622 15:25:42.067586       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.NetworkPolicy ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069176531Z W0622 15:25:42.067676       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ResourceQuota ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069189039Z W0622 15:25:42.067729       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Endpoints ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069196013Z W0622 15:25:42.067743       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Pod ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069202143Z W0622 15:25:42.067760       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1alpha1.ExternalAdmissionHookConfiguration ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069208785Z W0622 15:25:42.067787       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Node ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069214870Z W0622 15:25:42.067868       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.PodSecurityPolicy ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069221836Z W0622 15:25:42.067895       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Job ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069228047Z W0622 15:25:42.067913       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.StorageClass ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069435175Z W0622 15:25:42.068939       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.HorizontalPodAutoscaler ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069447139Z W0622 15:25:42.069019       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.DaemonSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069451391Z W0622 15:25:42.069071       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Namespace ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069455360Z W0622 15:25:42.069144       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ReplicationController ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069464259Z W0622 15:25:42.069191       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ServiceAccount ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069468392Z W0622 15:25:42.069208       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Ingress ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069473069Z W0622 15:25:42.069255       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.ControllerRevision ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:42.069490136Z W0622 15:25:42.069270       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.CronJob ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:48.976891320Z W0622 15:25:48.972440       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.NetworkPolicy ended with: too old resource version: 3836 (97991)
2018-06-22T15:25:48.991795329Z W0622 15:25:48.987730       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.PodDisruptionBudget ended with: too old resource version: 3836 (97991)
2018-06-22T15:25:48.991814501Z W0622 15:25:48.990519       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Pod ended with: too old resource version: 4248 (97991)
2018-06-22T15:25:48.991822763Z W0622 15:25:48.990602       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.ControllerRevision ended with: too old resource version: 3846 (97991)
2018-06-22T15:25:48.991829465Z W0622 15:25:48.990665       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PersistentVolumeClaim ended with: too old resource version: 3835 (97991)
2018-06-22T15:25:48.991835710Z W0622 15:25:48.990736       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.HorizontalPodAutoscaler ended with: too old resource version: 3836 (97991)
2018-06-22T15:25:48.991841860Z W0622 15:25:48.990807       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.StorageClass ended with: too old resource version: 3836 (97991)
2018-06-22T15:25:48.991847765Z W0622 15:25:48.990871       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Service ended with: too old resource version: 3835 (97991)
2018-06-22T15:25:48.991854238Z W0622 15:25:48.990932       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.PodSecurityPolicy ended with: too old resource version: 3836 (97991)
2018-06-22T15:25:49.011070298Z W0622 15:25:49.003829       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ResourceQuota ended with: too old resource version: 3835 (97991)
2018-06-22T15:25:49.011080237Z W0622 15:25:49.003901       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Job ended with: too old resource version: 3836 (97991)
2018-06-22T15:25:49.011086539Z W0622 15:25:49.003987       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Ingress ended with: too old resource version: 3836 (97991)
2018-06-22T15:25:49.011092611Z W0622 15:25:49.009786       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ConfigMap ended with: too old resource version: 3844 (97991)
2018-06-22T15:25:49.011098524Z W0622 15:25:49.009858       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PodTemplate ended with: too old resource version: 3835 (97991)
2018-06-22T15:25:49.011104551Z W0622 15:25:49.009922       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ServiceAccount ended with: too old resource version: 3835 (97991)
2018-06-22T15:25:49.011110492Z W0622 15:25:49.010027       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Secret ended with: too old resource version: 3835 (97991)
2018-06-22T15:25:49.011117587Z W0622 15:25:49.010089       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.CronJob ended with: too old resource version: 3836 (97991)
2018-06-22T15:25:49.017940536Z W0622 15:25:49.017533       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Deployment ended with: too old resource version: 4053 (97991)
2018-06-22T15:25:49.017958470Z W0622 15:25:49.017606       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.DaemonSet ended with: too old resource version: 4146 (97991)
2018-06-22T15:25:49.017966149Z W0622 15:25:49.017673       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta2.ReplicaSet ended with: too old resource version: 4052 (97991)
2018-06-22T15:25:49.017972045Z W0622 15:25:49.017734       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.CertificateSigningRequest ended with: too old resource version: 3836 (97991)
2018-06-22T15:25:49.024287303Z W0622 15:25:49.023297       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.LimitRange ended with: too old resource version: 3835 (97991)
2018-06-22T15:25:49.024303712Z W0622 15:25:49.023369       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Deployment ended with: too old resource version: 4053 (97991)
2018-06-22T15:25:49.024311235Z W0622 15:25:49.023416       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta2.DaemonSet ended with: too old resource version: 4146 (97991)
2018-06-22T15:25:49.024317339Z W0622 15:25:49.023461       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1alpha1.ExternalAdmissionHookConfiguration ended with: too old resource version: 3836 (97991)
2018-06-22T15:25:49.024331842Z W0622 15:25:49.023497       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1alpha1.InitializerConfiguration ended with: too old resource version: 3836 (97991)
2018-06-22T15:25:49.024338115Z W0622 15:25:49.023532       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.StatefulSet ended with: too old resource version: 3836 (97991)
2018-06-22T15:25:49.024343760Z W0622 15:25:49.023559       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PersistentVolume ended with: too old resource version: 3835 (97991)
2018-06-22T15:25:49.024349201Z W0622 15:25:49.023592       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.ReplicaSet ended with: too old resource version: 4052 (97991)
2018-06-22T15:25:49.024355168Z W0622 15:25:49.023621       1 reflector.go:334] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: watch of <nil> ended with: too old resource version: 3836 (97991)
2018-06-22T15:25:49.024361269Z W0622 15:25:49.023665       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ReplicationController ended with: too old resource version: 3835 (97991)
2018-06-22T15:25:49.024367897Z W0622 15:25:49.023693       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Namespace ended with: too old resource version: 3835 (97991)
2018-06-22T15:25:49.024373625Z W0622 15:25:49.023732       1 reflector.go:334] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: watch of <nil> ended with: too old resource version: 3836 (97991)
2018-06-22T15:25:54.536605074Z W0622 15:25:54.534786       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ResourceQuota ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537782887Z W0622 15:25:54.535830       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Secret ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537800897Z W0622 15:25:54.535963       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.PodDisruptionBudget ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537809617Z W0622 15:25:54.536162       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.NetworkPolicy ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537816694Z W0622 15:25:54.536275       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Deployment ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537829914Z W0622 15:25:54.536426       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.CertificateSigningRequest ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537836544Z W0622 15:25:54.536487       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PodTemplate ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537844905Z W0622 15:25:54.536554       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ConfigMap ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537851815Z W0622 15:25:54.536670       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Ingress ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537858537Z W0622 15:25:54.536760       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.ControllerRevision ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537864915Z W0622 15:25:54.536826       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Deployment ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537871217Z W0622 15:25:54.536880       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.LimitRange ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537877313Z W0622 15:25:54.536976       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PersistentVolumeClaim ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537884440Z W0622 15:25:54.537058       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Node ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537890813Z W0622 15:25:54.537128       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Service ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537896907Z W0622 15:25:54.537191       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.ReplicaSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537907140Z W0622 15:25:54.537246       1 reflector.go:334] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: watch of <nil> ended with: very short watch: k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537913831Z W0622 15:25:54.537316       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Endpoints ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.537920097Z W0622 15:25:54.537373       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta2.ReplicaSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.541225496Z W0622 15:25:54.539772       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1alpha1.ExternalAdmissionHookConfiguration ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.549502388Z W0622 15:25:54.543338       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Job ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.549515270Z W0622 15:25:54.543452       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.HorizontalPodAutoscaler ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.549520174Z W0622 15:25:54.543549       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.StorageClass ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.549524243Z W0622 15:25:54.543642       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.CronJob ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.549528259Z W0622 15:25:54.543732       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PersistentVolume ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.549532372Z W0622 15:25:54.543821       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.DaemonSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.549542796Z W0622 15:25:54.543906       1 reflector.go:334] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: watch of <nil> ended with: very short watch: k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.549547395Z W0622 15:25:54.544036       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ReplicationController ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.549551282Z W0622 15:25:54.544133       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta2.DaemonSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.549555202Z W0622 15:25:54.544289       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Namespace ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.549559120Z W0622 15:25:54.544378       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1alpha1.InitializerConfiguration ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.549563053Z W0622 15:25:54.544463       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.PodSecurityPolicy ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.549567876Z W0622 15:25:54.544546       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Pod ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.549571817Z W0622 15:25:54.544634       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ServiceAccount ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:54.549575687Z W0622 15:25:54.544733       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.StatefulSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:25:55.130016402Z W0622 15:25:55.123084       1 garbagecollector.go:609] failed to discover preferred resources: %vGet https://proxy.local:6444/api: EOF
2018-06-22T15:25:55.561167191Z E0622 15:25:55.550783       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ResourceQuota: Get https://proxy.local:6444/api/v1/resourcequotas?resourceVersion=0: EOF
2018-06-22T15:25:55.566026080Z E0622 15:25:55.561342       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.StatefulSet: Get https://proxy.local:6444/apis/apps/v1beta1/statefulsets?resourceVersion=0: EOF
2018-06-22T15:25:55.566044665Z E0622 15:25:55.561353       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PodTemplate: Get https://proxy.local:6444/api/v1/podtemplates?resourceVersion=0: EOF
2018-06-22T15:25:55.566051817Z E0622 15:25:55.561453       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodDisruptionBudget: Get https://proxy.local:6444/apis/policy/v1beta1/poddisruptionbudgets?resourceVersion=0: EOF
2018-06-22T15:25:55.566058334Z E0622 15:25:55.561533       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Ingress: Get https://proxy.local:6444/apis/extensions/v1beta1/ingresses?resourceVersion=0: EOF
2018-06-22T15:25:55.566064525Z E0622 15:25:55.561605       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.NetworkPolicy: Get https://proxy.local:6444/apis/networking.k8s.io/v1/networkpolicies?resourceVersion=0: EOF
2018-06-22T15:25:55.566070952Z E0622 15:25:55.561677       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Secret: Get https://proxy.local:6444/api/v1/secrets?resourceVersion=0: EOF
2018-06-22T15:25:55.566076918Z E0622 15:25:55.561757       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ConfigMap: Get https://proxy.local:6444/api/v1/configmaps?resourceVersion=0: EOF
2018-06-22T15:25:55.566083110Z E0622 15:25:55.561831       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Deployment: Get https://proxy.local:6444/apis/extensions/v1beta1/deployments?resourceVersion=0: EOF
2018-06-22T15:25:55.566090257Z E0622 15:25:55.561899       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.LimitRange: Get https://proxy.local:6444/api/v1/limitranges?resourceVersion=0: EOF
2018-06-22T15:25:55.566096535Z E0622 15:25:55.562007       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Node: Get https://proxy.local:6444/api/v1/nodes?resourceVersion=0: EOF
2018-06-22T15:25:55.566102522Z E0622 15:25:55.562083       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Endpoints: Get https://proxy.local:6444/api/v1/endpoints?resourceVersion=0: EOF
2018-06-22T15:25:55.566108631Z E0622 15:25:55.562160       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Service: Get https://proxy.local:6444/api/v1/services?resourceVersion=0: EOF
2018-06-22T15:25:55.566114598Z E0622 15:25:55.562236       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.ControllerRevision: Get https://proxy.local:6444/apis/apps/v1beta1/controllerrevisions?resourceVersion=0: EOF
2018-06-22T15:25:55.566120991Z E0622 15:25:55.562306       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/extensions/v1beta1/networkpolicies?resourceVersion=0: EOF
2018-06-22T15:25:55.566135141Z E0622 15:25:55.562385       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.ReplicaSet: Get https://proxy.local:6444/apis/extensions/v1beta1/replicasets?resourceVersion=0: EOF
2018-06-22T15:25:55.566142002Z E0622 15:25:55.562457       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Deployment: Get https://proxy.local:6444/apis/apps/v1beta1/deployments?resourceVersion=0: EOF
2018-06-22T15:25:55.566148126Z E0622 15:25:55.562527       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.CertificateSigningRequest: Get https://proxy.local:6444/apis/certificates.k8s.io/v1beta1/certificatesigningrequests?resourceVersion=0: EOF
2018-06-22T15:25:55.566171832Z E0622 15:25:55.562605       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PersistentVolumeClaim: Get https://proxy.local:6444/api/v1/persistentvolumeclaims?resourceVersion=0: EOF
2018-06-22T15:25:55.567202692Z E0622 15:25:55.565355       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta2.ReplicaSet: Get https://proxy.local:6444/apis/apps/v1beta2/replicasets?resourceVersion=0: EOF
2018-06-22T15:25:55.567220913Z E0622 15:25:55.566782       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.HorizontalPodAutoscaler: Get https://proxy.local:6444/apis/autoscaling/v1/horizontalpodautoscalers?resourceVersion=0: EOF
2018-06-22T15:25:55.567228946Z E0622 15:25:55.566865       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Job: Get https://proxy.local:6444/apis/batch/v1/jobs?resourceVersion=0: EOF
2018-06-22T15:25:55.567522532Z E0622 15:25:55.567040       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1alpha1.ExternalAdmissionHookConfiguration: Get https://proxy.local:6444/apis/admissionregistration.k8s.io/v1alpha1/externaladmissionhookconfigurations?resourceVersion=0: EOF
2018-06-22T15:25:55.567535789Z E0622 15:25:55.567134       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PersistentVolume: Get https://proxy.local:6444/api/v1/persistentvolumes?resourceVersion=0: EOF
2018-06-22T15:25:55.567542309Z E0622 15:25:55.567202       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Namespace: Get https://proxy.local:6444/api/v1/namespaces?resourceVersion=0: EOF
2018-06-22T15:25:55.567548287Z E0622 15:25:55.567271       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ReplicationController: Get https://proxy.local:6444/api/v1/replicationcontrollers?resourceVersion=0: EOF
2018-06-22T15:25:55.567554404Z E0622 15:25:55.567342       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/compose.docker.com/v1beta1/stacks?resourceVersion=0: EOF
2018-06-22T15:25:55.567561082Z E0622 15:25:55.567406       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodSecurityPolicy: Get https://proxy.local:6444/apis/extensions/v1beta1/podsecuritypolicies?resourceVersion=0: EOF
2018-06-22T15:25:55.571170945Z E0622 15:25:55.569747       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.DaemonSet: Get https://proxy.local:6444/apis/extensions/v1beta1/daemonsets?resourceVersion=0: EOF
2018-06-22T15:25:55.571188553Z E0622 15:25:55.569841       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.StorageClass: Get https://proxy.local:6444/apis/storage.k8s.io/v1/storageclasses?resourceVersion=0: EOF
2018-06-22T15:25:55.571196151Z E0622 15:25:55.569914       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.CronJob: Get https://proxy.local:6444/apis/batch/v1beta1/cronjobs?resourceVersion=0: EOF
2018-06-22T15:25:55.571202403Z E0622 15:25:55.570023       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta2.DaemonSet: Get https://proxy.local:6444/apis/apps/v1beta2/daemonsets?resourceVersion=0: EOF
2018-06-22T15:25:55.572439165Z E0622 15:25:55.572227       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1alpha1.InitializerConfiguration: Get https://proxy.local:6444/apis/admissionregistration.k8s.io/v1alpha1/initializerconfigurations?resourceVersion=0: EOF
2018-06-22T15:25:55.621324953Z E0622 15:25:55.621067       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Pod: Get https://proxy.local:6444/api/v1/pods?resourceVersion=0: EOF
2018-06-22T15:25:55.670997120Z E0622 15:25:55.670820       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ServiceAccount: Get https://proxy.local:6444/api/v1/serviceaccounts?resourceVersion=0: EOF
2018-06-22T15:25:56.000224211Z E0622 15:25:55.997381       1 leaderelection.go:224] error retrieving resource lock kube-system/kube-controller-manager: Get https://proxy.local:6444/api/v1/namespaces/kube-system/endpoints/kube-controller-manager: EOF
2018-06-22T15:25:56.555625553Z E0622 15:25:56.555425       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ResourceQuota: Get https://proxy.local:6444/api/v1/resourcequotas?resourceVersion=0: EOF
2018-06-22T15:25:56.562873306Z E0622 15:25:56.562665       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.StatefulSet: Get https://proxy.local:6444/apis/apps/v1beta1/statefulsets?resourceVersion=0: EOF
2018-06-22T15:25:56.564831750Z E0622 15:25:56.564587       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PodTemplate: Get https://proxy.local:6444/api/v1/podtemplates?resourceVersion=0: EOF
2018-06-22T15:25:56.574560450Z E0622 15:25:56.573567       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Ingress: Get https://proxy.local:6444/apis/extensions/v1beta1/ingresses?resourceVersion=0: EOF
2018-06-22T15:25:56.574574284Z E0622 15:25:56.573658       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodDisruptionBudget: Get https://proxy.local:6444/apis/policy/v1beta1/poddisruptionbudgets?resourceVersion=0: EOF
2018-06-22T15:25:56.574589926Z E0622 15:25:56.573758       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.NetworkPolicy: Get https://proxy.local:6444/apis/networking.k8s.io/v1/networkpolicies?resourceVersion=0: EOF
2018-06-22T15:25:56.584012309Z E0622 15:25:56.581366       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Secret: Get https://proxy.local:6444/api/v1/secrets?resourceVersion=0: EOF
2018-06-22T15:25:56.584031248Z E0622 15:25:56.581478       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ConfigMap: Get https://proxy.local:6444/api/v1/configmaps?resourceVersion=0: EOF
2018-06-22T15:25:56.602634225Z E0622 15:25:56.602027       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.LimitRange: Get https://proxy.local:6444/api/v1/limitranges?resourceVersion=0: EOF
2018-06-22T15:25:56.602650384Z E0622 15:25:56.602209       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Service: Get https://proxy.local:6444/api/v1/services?resourceVersion=0: EOF
2018-06-22T15:25:56.602655143Z E0622 15:25:56.602319       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Deployment: Get https://proxy.local:6444/apis/extensions/v1beta1/deployments?resourceVersion=0: EOF
2018-06-22T15:25:56.613671573Z E0622 15:25:56.611262       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/compose.docker.com/v1beta1/stacks?resourceVersion=0: EOF
2018-06-22T15:25:56.613690518Z E0622 15:25:56.611399       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/extensions/v1beta1/networkpolicies?resourceVersion=0: EOF
2018-06-22T15:25:56.613698413Z E0622 15:25:56.611500       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Node: Get https://proxy.local:6444/api/v1/nodes?resourceVersion=0: EOF
2018-06-22T15:25:56.613704706Z E0622 15:25:56.611589       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.CertificateSigningRequest: Get https://proxy.local:6444/apis/certificates.k8s.io/v1beta1/certificatesigningrequests?resourceVersion=0: EOF
2018-06-22T15:25:56.613711547Z E0622 15:25:56.611676       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Endpoints: Get https://proxy.local:6444/api/v1/endpoints?resourceVersion=0: EOF
2018-06-22T15:25:56.613717879Z E0622 15:25:56.611776       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.ControllerRevision: Get https://proxy.local:6444/apis/apps/v1beta1/controllerrevisions?resourceVersion=0: EOF
2018-06-22T15:25:56.613724174Z E0622 15:25:56.611869       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Deployment: Get https://proxy.local:6444/apis/apps/v1beta1/deployments?resourceVersion=0: EOF
2018-06-22T15:25:56.613730604Z E0622 15:25:56.611991       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.ReplicaSet: Get https://proxy.local:6444/apis/extensions/v1beta1/replicasets?resourceVersion=0: EOF
2018-06-22T15:25:56.613745320Z E0622 15:25:56.612080       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PersistentVolumeClaim: Get https://proxy.local:6444/api/v1/persistentvolumeclaims?resourceVersion=0: EOF
2018-06-22T15:25:56.624322221Z E0622 15:25:56.624137       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta2.ReplicaSet: Get https://proxy.local:6444/apis/apps/v1beta2/replicasets?resourceVersion=0: EOF
2018-06-22T15:25:56.675381501Z E0622 15:25:56.675133       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1alpha1.ExternalAdmissionHookConfiguration: Get https://proxy.local:6444/apis/admissionregistration.k8s.io/v1alpha1/externaladmissionhookconfigurations?resourceVersion=0: EOF
2018-06-22T15:25:56.727400625Z E0622 15:25:56.727172       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.HorizontalPodAutoscaler: Get https://proxy.local:6444/apis/autoscaling/v1/horizontalpodautoscalers?resourceVersion=0: EOF
2018-06-22T15:25:56.771358203Z E0622 15:25:56.771073       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Job: Get https://proxy.local:6444/apis/batch/v1/jobs?resourceVersion=0: EOF
2018-06-22T15:25:56.821310296Z E0622 15:25:56.821038       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PersistentVolume: Get https://proxy.local:6444/api/v1/persistentvolumes?resourceVersion=0: EOF
2018-06-22T15:25:56.871026470Z E0622 15:25:56.870864       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Namespace: Get https://proxy.local:6444/api/v1/namespaces?resourceVersion=0: EOF
2018-06-22T15:25:56.921751909Z E0622 15:25:56.921492       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ReplicationController: Get https://proxy.local:6444/api/v1/replicationcontrollers?resourceVersion=0: EOF
2018-06-22T15:25:56.971334624Z E0622 15:25:56.971181       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodSecurityPolicy: Get https://proxy.local:6444/apis/extensions/v1beta1/podsecuritypolicies?resourceVersion=0: EOF
2018-06-22T15:25:57.021193005Z E0622 15:25:57.020942       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.DaemonSet: Get https://proxy.local:6444/apis/extensions/v1beta1/daemonsets?resourceVersion=0: EOF
2018-06-22T15:25:57.071086112Z E0622 15:25:57.070886       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.StorageClass: Get https://proxy.local:6444/apis/storage.k8s.io/v1/storageclasses?resourceVersion=0: EOF
2018-06-22T15:25:57.127537685Z E0622 15:25:57.126358       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.CronJob: Get https://proxy.local:6444/apis/batch/v1beta1/cronjobs?resourceVersion=0: EOF
2018-06-22T15:25:57.171382583Z E0622 15:25:57.171174       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta2.DaemonSet: Get https://proxy.local:6444/apis/apps/v1beta2/daemonsets?resourceVersion=0: EOF
2018-06-22T15:25:57.221318551Z E0622 15:25:57.221053       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1alpha1.InitializerConfiguration: Get https://proxy.local:6444/apis/admissionregistration.k8s.io/v1alpha1/initializerconfigurations?resourceVersion=0: EOF
2018-06-22T15:25:57.271219126Z E0622 15:25:57.270920       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Pod: Get https://proxy.local:6444/api/v1/pods?resourceVersion=0: EOF
2018-06-22T15:25:57.321509234Z E0622 15:25:57.321203       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ServiceAccount: Get https://proxy.local:6444/api/v1/serviceaccounts?resourceVersion=0: EOF
2018-06-22T15:25:57.557514790Z E0622 15:25:57.557292       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ResourceQuota: Get https://proxy.local:6444/api/v1/resourcequotas?resourceVersion=0: EOF
2018-06-22T15:25:57.564269849Z E0622 15:25:57.563987       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.StatefulSet: Get https://proxy.local:6444/apis/apps/v1beta1/statefulsets?resourceVersion=0: EOF
2018-06-22T15:25:57.566264343Z E0622 15:25:57.566061       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PodTemplate: Get https://proxy.local:6444/api/v1/podtemplates?resourceVersion=0: EOF
2018-06-22T15:25:57.575969354Z E0622 15:25:57.575574       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Ingress: Get https://proxy.local:6444/apis/extensions/v1beta1/ingresses?resourceVersion=0: EOF
2018-06-22T15:25:57.577471090Z E0622 15:25:57.577234       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodDisruptionBudget: Get https://proxy.local:6444/apis/policy/v1beta1/poddisruptionbudgets?resourceVersion=0: EOF
2018-06-22T15:25:57.612811465Z E0622 15:25:57.612604       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/compose.docker.com/v1beta1/stacks?resourceVersion=0: EOF
2018-06-22T15:25:57.614199874Z E0622 15:25:57.614093       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/extensions/v1beta1/networkpolicies?resourceVersion=0: EOF
2018-06-22T15:25:57.621391155Z E0622 15:25:57.621165       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.NetworkPolicy: Get https://proxy.local:6444/apis/networking.k8s.io/v1/networkpolicies?resourceVersion=0: EOF
2018-06-22T15:25:57.670996269Z E0622 15:25:57.670851       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Secret: Get https://proxy.local:6444/api/v1/secrets?resourceVersion=0: EOF
2018-06-22T15:25:57.722985765Z E0622 15:25:57.722765       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ConfigMap: Get https://proxy.local:6444/api/v1/configmaps?resourceVersion=0: EOF
2018-06-22T15:25:57.772984772Z E0622 15:25:57.772673       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.LimitRange: Get https://proxy.local:6444/api/v1/limitranges?resourceVersion=0: EOF
2018-06-22T15:25:57.829729391Z E0622 15:25:57.829104       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Service: Get https://proxy.local:6444/api/v1/services?resourceVersion=0: EOF
2018-06-22T15:25:57.875341477Z E0622 15:25:57.874858       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Deployment: Get https://proxy.local:6444/apis/extensions/v1beta1/deployments?resourceVersion=0: EOF
2018-06-22T15:25:57.921203078Z E0622 15:25:57.920968       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Node: Get https://proxy.local:6444/api/v1/nodes?resourceVersion=0: EOF
2018-06-22T15:25:57.975770071Z E0622 15:25:57.975435       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.CertificateSigningRequest: Get https://proxy.local:6444/apis/certificates.k8s.io/v1beta1/certificatesigningrequests?resourceVersion=0: EOF
2018-06-22T15:25:57.989131807Z E0622 15:25:57.988792       1 leaderelection.go:224] error retrieving resource lock kube-system/kube-controller-manager: Get https://proxy.local:6444/api/v1/namespaces/kube-system/endpoints/kube-controller-manager: EOF
2018-06-22T15:25:58.023659712Z E0622 15:25:58.023356       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Endpoints: Get https://proxy.local:6444/api/v1/endpoints?resourceVersion=0: EOF
2018-06-22T15:25:58.086366515Z E0622 15:25:58.070735       1 cronjob_controller.go:113] can't list Jobs: Get https://proxy.local:6444/apis/batch/v1/jobs: EOF
2018-06-22T15:25:58.086386383Z E0622 15:25:58.076119       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.ControllerRevision: Get https://proxy.local:6444/apis/apps/v1beta1/controllerrevisions?resourceVersion=0: EOF
2018-06-22T15:25:58.129512760Z E0622 15:25:58.121639       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Deployment: Get https://proxy.local:6444/apis/apps/v1beta1/deployments?resourceVersion=0: EOF
2018-06-22T15:25:58.174402448Z E0622 15:25:58.174139       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.ReplicaSet: Get https://proxy.local:6444/apis/extensions/v1beta1/replicasets?resourceVersion=0: EOF
2018-06-22T15:25:58.224204416Z E0622 15:25:58.221146       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PersistentVolumeClaim: Get https://proxy.local:6444/api/v1/persistentvolumeclaims?resourceVersion=0: EOF
2018-06-22T15:25:58.271330859Z E0622 15:25:58.271036       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta2.ReplicaSet: Get https://proxy.local:6444/apis/apps/v1beta2/replicasets?resourceVersion=0: EOF
2018-06-22T15:25:58.321140786Z E0622 15:25:58.320900       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1alpha1.ExternalAdmissionHookConfiguration: Get https://proxy.local:6444/apis/admissionregistration.k8s.io/v1alpha1/externaladmissionhookconfigurations?resourceVersion=0: EOF
2018-06-22T15:25:58.371185220Z E0622 15:25:58.370916       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.HorizontalPodAutoscaler: Get https://proxy.local:6444/apis/autoscaling/v1/horizontalpodautoscalers?resourceVersion=0: EOF
2018-06-22T15:25:58.421510091Z E0622 15:25:58.421218       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Job: Get https://proxy.local:6444/apis/batch/v1/jobs?resourceVersion=0: EOF
2018-06-22T15:25:58.471531315Z E0622 15:25:58.471269       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PersistentVolume: Get https://proxy.local:6444/api/v1/persistentvolumes?resourceVersion=0: EOF
2018-06-22T15:25:58.521431295Z E0622 15:25:58.521173       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Namespace: Get https://proxy.local:6444/api/v1/namespaces?resourceVersion=0: EOF
2018-06-22T15:25:58.571920865Z E0622 15:25:58.571699       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ReplicationController: Get https://proxy.local:6444/api/v1/replicationcontrollers?resourceVersion=0: EOF
2018-06-22T15:25:58.614231221Z E0622 15:25:58.613998       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/compose.docker.com/v1beta1/stacks?resourceVersion=0: EOF
2018-06-22T15:25:58.615568667Z E0622 15:25:58.615312       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/extensions/v1beta1/networkpolicies?resourceVersion=0: EOF
2018-06-22T15:25:58.621019588Z E0622 15:25:58.620770       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodSecurityPolicy: Get https://proxy.local:6444/apis/extensions/v1beta1/podsecuritypolicies?resourceVersion=0: EOF
2018-06-22T15:25:58.674305182Z E0622 15:25:58.674112       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.DaemonSet: Get https://proxy.local:6444/apis/extensions/v1beta1/daemonsets?resourceVersion=0: EOF
2018-06-22T15:25:58.723169291Z E0622 15:25:58.722786       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.StorageClass: Get https://proxy.local:6444/apis/storage.k8s.io/v1/storageclasses?resourceVersion=0: EOF
2018-06-22T15:25:58.770980735Z E0622 15:25:58.770770       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.CronJob: Get https://proxy.local:6444/apis/batch/v1beta1/cronjobs?resourceVersion=0: EOF
2018-06-22T15:25:58.821179970Z E0622 15:25:58.820927       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta2.DaemonSet: Get https://proxy.local:6444/apis/apps/v1beta2/daemonsets?resourceVersion=0: EOF
2018-06-22T15:25:58.871307795Z E0622 15:25:58.871029       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1alpha1.InitializerConfiguration: Get https://proxy.local:6444/apis/admissionregistration.k8s.io/v1alpha1/initializerconfigurations?resourceVersion=0: EOF
2018-06-22T15:25:58.920978964Z E0622 15:25:58.920786       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Pod: Get https://proxy.local:6444/api/v1/pods?resourceVersion=0: EOF
2018-06-22T15:25:58.983533057Z E0622 15:25:58.977566       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ServiceAccount: Get https://proxy.local:6444/api/v1/serviceaccounts?resourceVersion=0: EOF
2018-06-22T15:25:59.021118395Z E0622 15:25:59.020939       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ResourceQuota: Get https://proxy.local:6444/api/v1/resourcequotas?resourceVersion=0: EOF
2018-06-22T15:25:59.071109461Z E0622 15:25:59.070920       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.StatefulSet: Get https://proxy.local:6444/apis/apps/v1beta1/statefulsets?resourceVersion=0: EOF
2018-06-22T15:25:59.121015225Z E0622 15:25:59.120817       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PodTemplate: Get https://proxy.local:6444/api/v1/podtemplates?resourceVersion=0: EOF
2018-06-22T15:25:59.171262673Z E0622 15:25:59.171020       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Ingress: Get https://proxy.local:6444/apis/extensions/v1beta1/ingresses?resourceVersion=0: EOF
2018-06-22T15:25:59.190376435Z I0622 15:25:59.190176       1 node_controller.go:836] Controller detected that zone  is now in state PartialDisruption.
2018-06-22T15:25:59.221080798Z E0622 15:25:59.220868       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodDisruptionBudget: Get https://proxy.local:6444/apis/policy/v1beta1/poddisruptionbudgets?resourceVersion=0: EOF
2018-06-22T15:25:59.271005031Z E0622 15:25:59.270815       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.NetworkPolicy: Get https://proxy.local:6444/apis/networking.k8s.io/v1/networkpolicies?resourceVersion=0: EOF
2018-06-22T15:25:59.322308163Z E0622 15:25:59.322093       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Secret: Get https://proxy.local:6444/api/v1/secrets?resourceVersion=0: EOF
2018-06-22T15:25:59.373156296Z E0622 15:25:59.372851       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ConfigMap: Get https://proxy.local:6444/api/v1/configmaps?resourceVersion=0: EOF
2018-06-22T15:26:29.192336087Z I0622 15:26:29.192050       1 node_controller.go:836] Controller detected that zone  is now in state Normal.
2018-06-22T15:27:09.972199954Z W0622 15:27:09.967807       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.StatefulSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.972223438Z W0622 15:27:09.967961       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PodTemplate ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.972231936Z W0622 15:27:09.968177       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ConfigMap ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.972244193Z W0622 15:27:09.968543       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.HorizontalPodAutoscaler ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.972251325Z W0622 15:27:09.968672       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PersistentVolume ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.972257484Z W0622 15:27:09.968881       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.StorageClass ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.972264972Z W0622 15:27:09.969227       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ServiceAccount ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.977989729Z W0622 15:27:09.972724       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Namespace ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978003798Z W0622 15:27:09.972862       1 reflector.go:334] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: watch of <nil> ended with: very short watch: k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978010792Z W0622 15:27:09.973021       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Service ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978017285Z W0622 15:27:09.973085       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ResourceQuota ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978023792Z W0622 15:27:09.973217       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.PodDisruptionBudget ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978030605Z W0622 15:27:09.973360       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1alpha1.InitializerConfiguration ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978052635Z W0622 15:27:09.973493       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Job ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978061249Z W0622 15:27:09.973645       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PersistentVolumeClaim ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978068197Z W0622 15:27:09.973779       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.ControllerRevision ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978075112Z W0622 15:27:09.973911       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Node ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978081474Z W0622 15:27:09.974068       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.DaemonSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978087802Z W0622 15:27:09.974205       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Ingress ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978094960Z W0622 15:27:09.977046       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Deployment ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978101898Z W0622 15:27:09.977136       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.LimitRange ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978108284Z W0622 15:27:09.977260       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta2.ReplicaSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978114324Z W0622 15:27:09.977426       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ReplicationController ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978120625Z W0622 15:27:09.977580       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.CertificateSigningRequest ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978132458Z W0622 15:27:09.977645       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.CronJob ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978139462Z W0622 15:27:09.977678       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.ReplicaSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978147416Z W0622 15:27:09.977706       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.NetworkPolicy ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978153980Z W0622 15:27:09.977740       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta2.DaemonSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978160264Z W0622 15:27:09.977762       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1alpha1.ExternalAdmissionHookConfiguration ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978166464Z W0622 15:27:09.977820       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Deployment ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978172917Z W0622 15:27:09.977881       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.PodSecurityPolicy ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978655300Z W0622 15:27:09.978194       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Secret ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978668476Z W0622 15:27:09.978253       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Endpoints ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978688861Z W0622 15:27:09.977208       1 reflector.go:334] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: watch of <nil> ended with: very short watch: k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:09.978704765Z W0622 15:27:09.978289       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Pod ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-22T15:27:10.302771819Z E0622 15:27:10.302473       1 leaderelection.go:224] error retrieving resource lock kube-system/kube-controller-manager: Get https://proxy.local:6444/api/v1/namespaces/kube-system/endpoints/kube-controller-manager: dial tcp 172.31.9.58:6444: getsockopt: connection refused
2018-06-22T15:27:20.971334498Z E0622 15:27:20.970934       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.StorageClass: Get https://proxy.local:6444/apis/storage.k8s.io/v1/storageclasses?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.971371376Z E0622 15:27:20.971019       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ServiceAccount: Get https://proxy.local:6444/api/v1/serviceaccounts?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.971380912Z E0622 15:27:20.971091       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ConfigMap: Get https://proxy.local:6444/api/v1/configmaps?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.971386448Z E0622 15:27:20.971106       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PersistentVolume: Get https://proxy.local:6444/api/v1/persistentvolumes?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.971392133Z E0622 15:27:20.971170       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.HorizontalPodAutoscaler: Get https://proxy.local:6444/apis/autoscaling/v1/horizontalpodautoscalers?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.971398457Z E0622 15:27:20.971242       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PodTemplate: Get https://proxy.local:6444/api/v1/podtemplates?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.971677797Z E0622 15:27:20.971438       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.StatefulSet: Get https://proxy.local:6444/apis/apps/v1beta1/statefulsets?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.978682121Z E0622 15:27:20.978417       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ReplicationController: Get https://proxy.local:6444/api/v1/replicationcontrollers?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.978699944Z E0622 15:27:20.978536       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta2.ReplicaSet: Get https://proxy.local:6444/apis/apps/v1beta2/replicasets?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.984712048Z E0622 15:27:20.984441       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Service: Get https://proxy.local:6444/api/v1/services?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.984742715Z E0622 15:27:20.984441       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.NetworkPolicy: Get https://proxy.local:6444/apis/networking.k8s.io/v1/networkpolicies?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.984750400Z E0622 15:27:20.984484       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Deployment: Get https://proxy.local:6444/apis/apps/v1beta1/deployments?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.984757208Z E0622 15:27:20.984598       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.ReplicaSet: Get https://proxy.local:6444/apis/extensions/v1beta1/replicasets?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.984765552Z E0622 15:27:20.984653       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/compose.docker.com/v1beta1/stacks?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.984772375Z E0622 15:27:20.984654       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta2.DaemonSet: Get https://proxy.local:6444/apis/apps/v1beta2/daemonsets?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.984876186Z E0622 15:27:20.984722       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodSecurityPolicy: Get https://proxy.local:6444/apis/extensions/v1beta1/podsecuritypolicies?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.984888305Z E0622 15:27:20.984773       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1alpha1.InitializerConfiguration: Get https://proxy.local:6444/apis/admissionregistration.k8s.io/v1alpha1/initializerconfigurations?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.985046760Z E0622 15:27:20.984829       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.CertificateSigningRequest: Get https://proxy.local:6444/apis/certificates.k8s.io/v1beta1/certificatesigningrequests?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.985058824Z E0622 15:27:20.984869       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Ingress: Get https://proxy.local:6444/apis/extensions/v1beta1/ingresses?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.985065616Z E0622 15:27:20.984916       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1alpha1.ExternalAdmissionHookConfiguration: Get https://proxy.local:6444/apis/admissionregistration.k8s.io/v1alpha1/externaladmissionhookconfigurations?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.985072454Z E0622 15:27:20.984972       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Node: Get https://proxy.local:6444/api/v1/nodes?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.985078773Z E0622 15:27:20.985020       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Pod: Get https://proxy.local:6444/api/v1/pods?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.985198572Z E0622 15:27:20.985057       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PersistentVolumeClaim: Get https://proxy.local:6444/api/v1/persistentvolumeclaims?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.985210411Z E0622 15:27:20.985094       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.ControllerRevision: Get https://proxy.local:6444/apis/apps/v1beta1/controllerrevisions?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.985217064Z E0622 15:27:20.985128       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.LimitRange: Get https://proxy.local:6444/api/v1/limitranges?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.985588920Z E0622 15:27:20.985394       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodDisruptionBudget: Get https://proxy.local:6444/apis/policy/v1beta1/poddisruptionbudgets?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.985601514Z E0622 15:27:20.985394       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Job: Get https://proxy.local:6444/apis/batch/v1/jobs?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.985608112Z E0622 15:27:20.985431       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.DaemonSet: Get https://proxy.local:6444/apis/extensions/v1beta1/daemonsets?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.985614609Z E0622 15:27:20.985440       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ResourceQuota: Get https://proxy.local:6444/api/v1/resourcequotas?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.985620927Z E0622 15:27:20.985474       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Namespace: Get https://proxy.local:6444/api/v1/namespaces?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.985627266Z E0622 15:27:20.985493       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Deployment: Get https://proxy.local:6444/apis/extensions/v1beta1/deployments?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.985633594Z E0622 15:27:20.985522       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/extensions/v1beta1/networkpolicies?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:20.985641012Z E0622 15:27:20.985533       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.CronJob: Get https://proxy.local:6444/apis/batch/v1beta1/cronjobs?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:21.021413218Z E0622 15:27:21.021161       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Secret: Get https://proxy.local:6444/api/v1/secrets?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:21.070951257Z E0622 15:27:21.070697       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Endpoints: Get https://proxy.local:6444/api/v1/endpoints?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:22.304926931Z E0622 15:27:22.303854       1 leaderelection.go:224] error retrieving resource lock kube-system/kube-controller-manager: Get https://proxy.local:6444/api/v1/namespaces/kube-system/endpoints/kube-controller-manager: net/http: TLS handshake timeout
2018-06-22T15:27:28.136333789Z E0622 15:27:28.136130       1 cronjob_controller.go:113] can't list Jobs: Get https://proxy.local:6444/apis/batch/v1/jobs: net/http: TLS handshake timeout
2018-06-22T15:27:31.973431558Z E0622 15:27:31.973213       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ServiceAccount: Get https://proxy.local:6444/api/v1/serviceaccounts?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.973450213Z E0622 15:27:31.973213       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.StorageClass: Get https://proxy.local:6444/apis/storage.k8s.io/v1/storageclasses?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.974028388Z E0622 15:27:31.973923       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ConfigMap: Get https://proxy.local:6444/api/v1/configmaps?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.975306420Z E0622 15:27:31.975175       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PersistentVolume: Get https://proxy.local:6444/api/v1/persistentvolumes?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.980040411Z E0622 15:27:31.979746       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PodTemplate: Get https://proxy.local:6444/api/v1/podtemplates?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.980056499Z E0622 15:27:31.979929       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.HorizontalPodAutoscaler: Get https://proxy.local:6444/apis/autoscaling/v1/horizontalpodautoscalers?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.980064069Z E0622 15:27:31.979929       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.StatefulSet: Get https://proxy.local:6444/apis/apps/v1beta1/statefulsets?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.987692308Z E0622 15:27:31.987537       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta2.ReplicaSet: Get https://proxy.local:6444/apis/apps/v1beta2/replicasets?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.988163649Z E0622 15:27:31.987917       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Deployment: Get https://proxy.local:6444/apis/apps/v1beta1/deployments?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.988536926Z E0622 15:27:31.988277       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.NetworkPolicy: Get https://proxy.local:6444/apis/networking.k8s.io/v1/networkpolicies?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.988548995Z E0622 15:27:31.988334       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ReplicationController: Get https://proxy.local:6444/api/v1/replicationcontrollers?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.988559436Z E0622 15:27:31.988465       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Service: Get https://proxy.local:6444/api/v1/services?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.992828832Z E0622 15:27:31.992605       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/compose.docker.com/v1beta1/stacks?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.992941203Z E0622 15:27:31.992811       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.ReplicaSet: Get https://proxy.local:6444/apis/extensions/v1beta1/replicasets?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.993182882Z E0622 15:27:31.992995       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta2.DaemonSet: Get https://proxy.local:6444/apis/apps/v1beta2/daemonsets?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.993516731Z E0622 15:27:31.993278       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodSecurityPolicy: Get https://proxy.local:6444/apis/extensions/v1beta1/podsecuritypolicies?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.994889237Z E0622 15:27:31.994571       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1alpha1.InitializerConfiguration: Get https://proxy.local:6444/apis/admissionregistration.k8s.io/v1alpha1/initializerconfigurations?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.994903094Z E0622 15:27:31.994571       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.CertificateSigningRequest: Get https://proxy.local:6444/apis/certificates.k8s.io/v1beta1/certificatesigningrequests?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.998123695Z E0622 15:27:31.997946       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1alpha1.ExternalAdmissionHookConfiguration: Get https://proxy.local:6444/apis/admissionregistration.k8s.io/v1alpha1/externaladmissionhookconfigurations?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.998141652Z E0622 15:27:31.998037       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Ingress: Get https://proxy.local:6444/apis/extensions/v1beta1/ingresses?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.998760364Z E0622 15:27:31.998478       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Node: Get https://proxy.local:6444/api/v1/nodes?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:31.999533990Z E0622 15:27:31.999293       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Pod: Get https://proxy.local:6444/api/v1/pods?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:32.000677715Z E0622 15:27:32.000479       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.PersistentVolumeClaim: Get https://proxy.local:6444/api/v1/persistentvolumeclaims?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:32.001918870Z E0622 15:27:32.001686       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.ControllerRevision: Get https://proxy.local:6444/apis/apps/v1beta1/controllerrevisions?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:32.003149121Z E0622 15:27:32.002886       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.LimitRange: Get https://proxy.local:6444/api/v1/limitranges?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:32.004277515Z E0622 15:27:32.004048       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.PodDisruptionBudget: Get https://proxy.local:6444/apis/policy/v1beta1/poddisruptionbudgets?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:32.005431444Z E0622 15:27:32.005205       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Job: Get https://proxy.local:6444/apis/batch/v1/jobs?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:32.006487863Z E0622 15:27:32.006346       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.DaemonSet: Get https://proxy.local:6444/apis/extensions/v1beta1/daemonsets?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:32.008242463Z E0622 15:27:32.007791       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.ResourceQuota: Get https://proxy.local:6444/api/v1/resourcequotas?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:32.008967987Z E0622 15:27:32.008813       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Namespace: Get https://proxy.local:6444/api/v1/namespaces?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:32.010634003Z E0622 15:27:32.010391       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.Deployment: Get https://proxy.local:6444/apis/extensions/v1beta1/deployments?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:32.011544143Z E0622 15:27:32.011395       1 reflector.go:205] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Failed to list <nil>: Get https://proxy.local:6444/apis/extensions/v1beta1/networkpolicies?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:32.020321516Z E0622 15:27:32.020101       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1beta1.CronJob: Get https://proxy.local:6444/apis/batch/v1beta1/cronjobs?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:32.076609105Z E0622 15:27:32.076466       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Secret: Get https://proxy.local:6444/api/v1/secrets?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:32.120589221Z E0622 15:27:32.120347       1 reflector.go:205] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Failed to list *v1.Endpoints: Get https://proxy.local:6444/api/v1/endpoints?resourceVersion=0: net/http: TLS handshake timeout
2018-06-22T15:27:32.304830971Z E0622 15:27:32.304551       1 leaderelection.go:224] error retrieving resource lock kube-system/kube-controller-manager: Get https://proxy.local:6444/api/v1/namespaces/kube-system/endpoints/kube-controller-manager: net/http: TLS handshake timeout
2018-06-22T15:27:32.304854017Z E0622 15:27:32.304587       1 event.go:260] Could not construct reference to: '&v1.Endpoints{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{sec:0, nsec:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Subsets:[]v1.EndpointSubset(nil)}' due to: 'selfLink was empty, can't make reference'. Will not report event: 'Normal' 'LeaderElection' 'ip-172-31-9-58.ec2.internal stopped leading'
2018-06-22T15:27:32.305009633Z I0622 15:27:32.304654       1 leaderelection.go:203] failed to renew lease kube-system/kube-controller-manager: timed out waiting for the condition
2018-06-22T15:27:32.305022412Z F0622 15:27:32.304788       1 controllermanager.go:195] leaderelection lost
2018-06-22T15:27:32.325463153Z I0622 15:27:32.325165       1 cronjob_controller.go:102] Shutting down CronJob Manager
2018-06-22T15:27:32.867983405Z I0622 15:27:32.867691       1 controllermanager.go:109] Version: v1.8.11-docker-8d637ae
2018-06-22T15:27:32.888681079Z I0622 15:27:32.888414       1 leaderelection.go:174] attempting to acquire leader lease...
2018-06-22T15:27:41.402188806Z I0622 15:27:41.401835       1 leaderelection.go:184] successfully acquired lease kube-system/kube-controller-manager
2018-06-22T15:27:41.402210992Z I0622 15:27:41.402063       1 event.go:218] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"kube-controller-manager", UID:"1e44023a-7590-11e8-8955-0242ac110012", APIVersion:"v1", ResourceVersion:"98197", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' ip-172-31-9-58.ec2.internal became leader
2018-06-22T15:27:41.457899274Z I0622 15:27:41.457742       1 plugins.go:101] No cloud provider specified.
2018-06-22T15:27:41.461272746Z I0622 15:27:41.460316       1 controller_utils.go:1041] Waiting for caches to sync for tokens controller
2018-06-22T15:27:41.461925384Z E0622 15:27:41.461812       1 certificates.go:48] Failed to start certificate controller: error reading CA cert file "/etc/kubernetes/ca/ca.pem": open /etc/kubernetes/ca/ca.pem: no such file or directory
2018-06-22T15:27:41.461943074Z W0622 15:27:41.461834       1 controllermanager.go:488] Skipping "csrsigning"
2018-06-22T15:27:41.463891236Z W0622 15:27:41.463720       1 probe.go:215] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
2018-06-22T15:27:41.463907968Z E0622 15:27:41.463771       1 plugins.go:393] Error initializing dynamic plugin prober: Error (re-)creating driver directory: mkdir /usr/libexec: permission denied
2018-06-22T15:27:41.470329776Z I0622 15:27:41.464240       1 controllermanager.go:491] Started "attachdetach"
2018-06-22T15:27:41.470359281Z I0622 15:27:41.465030       1 attach_detach_controller.go:255] Starting attach detach controller
2018-06-22T15:27:41.470366505Z I0622 15:27:41.465042       1 controller_utils.go:1041] Waiting for caches to sync for attach detach controller
2018-06-22T15:27:41.470372026Z W0622 15:27:41.466091       1 shared_informer.go:304] resyncPeriod 82916069466373 is smaller than resyncCheckPeriod 83977325934530 and the informer has already started. Changing it to 83977325934530
2018-06-22T15:27:41.470378126Z I0622 15:27:41.466136       1 controllermanager.go:491] Started "resourcequota"
2018-06-22T15:27:41.470383605Z I0622 15:27:41.466394       1 resource_quota_controller.go:238] Starting resource quota controller
2018-06-22T15:27:41.470388768Z I0622 15:27:41.466416       1 controller_utils.go:1041] Waiting for caches to sync for resource quota controller
2018-06-22T15:27:41.470394308Z I0622 15:27:41.467715       1 controllermanager.go:491] Started "serviceaccount"
2018-06-22T15:27:41.470399785Z I0622 15:27:41.467997       1 serviceaccounts_controller.go:113] Starting service account controller
2018-06-22T15:27:41.470405120Z I0622 15:27:41.468020       1 controller_utils.go:1041] Waiting for caches to sync for service account controller
2018-06-22T15:27:41.470410867Z I0622 15:27:41.469725       1 controllermanager.go:491] Started "replicaset"
2018-06-22T15:27:41.473094770Z I0622 15:27:41.471438       1 replica_set.go:156] Starting replica set controller
2018-06-22T15:27:41.473111945Z I0622 15:27:41.471466       1 controller_utils.go:1041] Waiting for caches to sync for replica set controller
2018-06-22T15:27:41.474747457Z I0622 15:27:41.474087       1 controllermanager.go:491] Started "horizontalpodautoscaling"
2018-06-22T15:27:41.478176084Z I0622 15:27:41.474372       1 horizontal.go:145] Starting HPA controller
2018-06-22T15:27:41.478193562Z I0622 15:27:41.474398       1 controller_utils.go:1041] Waiting for caches to sync for HPA controller
2018-06-22T15:27:41.478200415Z I0622 15:27:41.475532       1 controllermanager.go:491] Started "statefulset"
2018-06-22T15:27:41.478206248Z I0622 15:27:41.476871       1 controllermanager.go:491] Started "ttl"
2018-06-22T15:27:41.478209879Z W0622 15:27:41.476889       1 controllermanager.go:475] "bootstrapsigner" is disabled
2018-06-22T15:27:41.478213313Z W0622 15:27:41.476897       1 controllermanager.go:475] "tokencleaner" is disabled
2018-06-22T15:27:41.478216782Z I0622 15:27:41.478045       1 stateful_set.go:150] Starting stateful set controller
2018-06-22T15:27:41.478220113Z I0622 15:27:41.478073       1 controller_utils.go:1041] Waiting for caches to sync for stateful set controller
2018-06-22T15:27:41.478347039Z I0622 15:27:41.478235       1 ttl_controller.go:116] Starting TTL controller
2018-06-22T15:27:41.478359946Z I0622 15:27:41.478259       1 controller_utils.go:1041] Waiting for caches to sync for TTL controller
2018-06-22T15:27:41.486513826Z I0622 15:27:41.485354       1 controllermanager.go:491] Started "replicationcontroller"
2018-06-22T15:27:41.486532546Z I0622 15:27:41.485619       1 replication_controller.go:151] Starting RC controller
2018-06-22T15:27:41.486548826Z I0622 15:27:41.485642       1 controller_utils.go:1041] Waiting for caches to sync for RC controller
2018-06-22T15:27:41.561717037Z I0622 15:27:41.560611       1 controller_utils.go:1048] Caches are synced for tokens controller
2018-06-22T15:27:41.569770221Z I0622 15:27:41.569570       1 controllermanager.go:491] Started "namespace"
2018-06-22T15:27:41.571216616Z I0622 15:27:41.570933       1 namespace_controller.go:186] Starting namespace controller
2018-06-22T15:27:41.571232855Z I0622 15:27:41.570966       1 controller_utils.go:1041] Waiting for caches to sync for namespace controller
2018-06-22T15:27:42.384416974Z I0622 15:27:42.383312       1 garbagecollector.go:136] Starting garbage collector controller
2018-06-22T15:27:42.384446184Z I0622 15:27:42.383351       1 controller_utils.go:1041] Waiting for caches to sync for garbage collector controller
2018-06-22T15:27:42.384455241Z I0622 15:27:42.383415       1 graph_builder.go:322] GraphBuilder running
2018-06-22T15:27:42.384461266Z I0622 15:27:42.383301       1 controllermanager.go:491] Started "garbagecollector"
2018-06-22T15:27:42.387416707Z I0622 15:27:42.387205       1 controllermanager.go:491] Started "disruption"
2018-06-22T15:27:42.389833665Z I0622 15:27:42.388999       1 disruption.go:288] Starting disruption controller
2018-06-22T15:27:42.389851022Z I0622 15:27:42.389016       1 controller_utils.go:1041] Waiting for caches to sync for disruption controller
2018-06-22T15:27:42.390024656Z E0622 15:27:42.389540       1 core.go:70] Failed to start service controller: WARNING: no cloud provider provided, services of type LoadBalancer will fail.
2018-06-22T15:27:42.390042226Z W0622 15:27:42.389557       1 controllermanager.go:488] Skipping "service"
2018-06-22T15:27:42.391825382Z I0622 15:27:42.391216       1 node_controller.go:249] Sending events to api server.
2018-06-22T15:27:42.391842878Z I0622 15:27:42.391326       1 taint_controller.go:158] Sending events to api server.
2018-06-22T15:27:42.391850437Z I0622 15:27:42.391394       1 controllermanager.go:491] Started "node"
2018-06-22T15:27:42.391856440Z I0622 15:27:42.391556       1 node_controller.go:515] Starting node controller
2018-06-22T15:27:42.391862259Z I0622 15:27:42.391580       1 controller_utils.go:1041] Waiting for caches to sync for node controller
2018-06-22T15:27:42.394082382Z I0622 15:27:42.393824       1 controllermanager.go:491] Started "persistentvolume-binder"
2018-06-22T15:27:42.394100097Z W0622 15:27:42.393843       1 core.go:128] Unsuccessful parsing of cluster CIDR : invalid CIDR address: 
2018-06-22T15:27:42.394107880Z I0622 15:27:42.393855       1 core.go:131] Will not configure cloud provider routes for allocate-node-cidrs: false, configure-cloud-routes: true.
2018-06-22T15:27:42.394114058Z W0622 15:27:42.393862       1 controllermanager.go:488] Skipping "route"
2018-06-22T15:27:42.394119957Z W0622 15:27:42.393871       1 controllermanager.go:488] Skipping "persistentvolume-expander"
2018-06-22T15:27:42.394570853Z I0622 15:27:42.394413       1 pv_controller_base.go:259] Starting persistent volume controller
2018-06-22T15:27:42.394597402Z I0622 15:27:42.394439       1 controller_utils.go:1041] Waiting for caches to sync for persistent volume controller
2018-06-22T15:27:42.396161790Z I0622 15:27:42.395891       1 controllermanager.go:491] Started "daemonset"
2018-06-22T15:27:42.398958333Z I0622 15:27:42.398750       1 controllermanager.go:491] Started "job"
2018-06-22T15:27:42.400269461Z I0622 15:27:42.399991       1 daemon_controller.go:230] Starting daemon sets controller
2018-06-22T15:27:42.400285999Z I0622 15:27:42.400022       1 controller_utils.go:1041] Waiting for caches to sync for daemon sets controller
2018-06-22T15:27:42.400292374Z I0622 15:27:42.400171       1 job_controller.go:138] Starting job controller
2018-06-22T15:27:42.400297825Z I0622 15:27:42.400195       1 controller_utils.go:1041] Waiting for caches to sync for job controller
2018-06-22T15:27:42.401025184Z I0622 15:27:42.400655       1 controllermanager.go:491] Started "deployment"
2018-06-22T15:27:42.403164884Z I0622 15:27:42.402381       1 controllermanager.go:491] Started "cronjob"
2018-06-22T15:27:42.406292523Z I0622 15:27:42.403114       1 deployment_controller.go:151] Starting deployment controller
2018-06-22T15:27:42.406310182Z I0622 15:27:42.403140       1 controller_utils.go:1041] Waiting for caches to sync for deployment controller
2018-06-22T15:27:42.406318392Z I0622 15:27:42.403379       1 cronjob_controller.go:98] Starting CronJob Manager
2018-06-22T15:27:42.406324432Z I0622 15:27:42.404282       1 controllermanager.go:491] Started "endpoint"
2018-06-22T15:27:42.406330405Z I0622 15:27:42.405980       1 controllermanager.go:491] Started "podgc"
2018-06-22T15:27:42.407797685Z I0622 15:27:42.407488       1 controllermanager.go:491] Started "csrapproving"
2018-06-22T15:27:42.408167548Z I0622 15:27:42.407895       1 endpoints_controller.go:153] Starting endpoint controller
2018-06-22T15:27:42.408185852Z I0622 15:27:42.407924       1 controller_utils.go:1041] Waiting for caches to sync for endpoint controller
2018-06-22T15:27:42.408697158Z I0622 15:27:42.408420       1 gc_controller.go:76] Starting GC controller
2018-06-22T15:27:42.408715522Z I0622 15:27:42.408443       1 controller_utils.go:1041] Waiting for caches to sync for GC controller
2018-06-22T15:27:42.409972704Z I0622 15:27:42.409058       1 certificate_controller.go:109] Starting certificate controller
2018-06-22T15:27:42.409990365Z I0622 15:27:42.409104       1 controller_utils.go:1041] Waiting for caches to sync for certificate controller
2018-06-22T15:27:42.447791036Z E0622 15:27:42.445417       1 actual_state_of_world.go:483] Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-10-96.ec2.internal"  does not exist
2018-06-22T15:27:42.447809623Z E0622 15:27:42.445434       1 actual_state_of_world.go:497] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-10-96.ec2.internal"  does not exist
2018-06-22T15:27:42.447817648Z E0622 15:27:42.445450       1 actual_state_of_world.go:483] Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-12-152.ec2.internal"  does not exist
2018-06-22T15:27:42.447833776Z E0622 15:27:42.445458       1 actual_state_of_world.go:497] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-12-152.ec2.internal"  does not exist
2018-06-22T15:27:42.447840541Z E0622 15:27:42.445741       1 actual_state_of_world.go:483] Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-18-229.ec2.internal"  does not exist
2018-06-22T15:27:42.447846216Z E0622 15:27:42.445751       1 actual_state_of_world.go:497] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-18-229.ec2.internal"  does not exist
2018-06-22T15:27:42.447852197Z E0622 15:27:42.445930       1 actual_state_of_world.go:483] Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-9-58.ec2.internal"  does not exist
2018-06-22T15:27:42.447857820Z E0622 15:27:42.446134       1 actual_state_of_world.go:497] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-9-58.ec2.internal"  does not exist
2018-06-22T15:27:42.465669170Z I0622 15:27:42.465221       1 controller_utils.go:1048] Caches are synced for attach detach controller
2018-06-22T15:27:42.466764996Z I0622 15:27:42.466673       1 controller_utils.go:1048] Caches are synced for resource quota controller
2018-06-22T15:27:42.468530964Z I0622 15:27:42.468274       1 controller_utils.go:1048] Caches are synced for service account controller
2018-06-22T15:27:42.471950352Z I0622 15:27:42.471581       1 controller_utils.go:1048] Caches are synced for namespace controller
2018-06-22T15:27:42.472509316Z I0622 15:27:42.471992       1 controller_utils.go:1048] Caches are synced for replica set controller
2018-06-22T15:27:42.475192380Z I0622 15:27:42.474598       1 controller_utils.go:1048] Caches are synced for HPA controller
2018-06-22T15:27:42.479224804Z I0622 15:27:42.478927       1 controller_utils.go:1048] Caches are synced for stateful set controller
2018-06-22T15:27:42.479239358Z I0622 15:27:42.479062       1 controller_utils.go:1048] Caches are synced for TTL controller
2018-06-22T15:27:42.483666532Z I0622 15:27:42.483578       1 controller_utils.go:1048] Caches are synced for garbage collector controller
2018-06-22T15:27:42.483683078Z I0622 15:27:42.483598       1 garbagecollector.go:145] Garbage collector: all resource monitors have synced. Proceeding to collect garbage
2018-06-22T15:27:42.485981952Z I0622 15:27:42.485850       1 controller_utils.go:1048] Caches are synced for RC controller
2018-06-22T15:27:42.489343480Z I0622 15:27:42.489237       1 controller_utils.go:1048] Caches are synced for disruption controller
2018-06-22T15:27:42.489359070Z I0622 15:27:42.489251       1 disruption.go:296] Sending events to api server.
2018-06-22T15:27:42.491948566Z I0622 15:27:42.491763       1 controller_utils.go:1048] Caches are synced for node controller
2018-06-22T15:27:42.491965310Z I0622 15:27:42.491855       1 node_controller.go:567] Initializing eviction metric for zone: 
2018-06-22T15:27:42.492434702Z W0622 15:27:42.491959       1 node_controller.go:920] Missing timestamp for Node ip-172-31-12-152.ec2.internal. Assuming now as a timestamp.
2018-06-22T15:27:42.492451400Z W0622 15:27:42.492012       1 node_controller.go:920] Missing timestamp for Node ip-172-31-18-229.ec2.internal. Assuming now as a timestamp.
2018-06-22T15:27:42.492458534Z I0622 15:27:42.492038       1 taint_controller.go:181] Starting NoExecuteTaintManager
2018-06-22T15:27:42.492462290Z I0622 15:27:42.492042       1 event.go:218] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-172-31-12-152.ec2.internal", UID:"31a722e9-7590-11e8-8955-0242ac110012", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node ip-172-31-12-152.ec2.internal event: Registered Node ip-172-31-12-152.ec2.internal in Controller
2018-06-22T15:27:42.492472775Z I0622 15:27:42.492086       1 event.go:218] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-172-31-18-229.ec2.internal", UID:"31ca3f1d-7590-11e8-8955-0242ac110012", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node ip-172-31-18-229.ec2.internal event: Registered Node ip-172-31-18-229.ec2.internal in Controller
2018-06-22T15:27:42.492477575Z I0622 15:27:42.492103       1 event.go:218] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-172-31-9-58.ec2.internal", UID:"1e876bf6-7590-11e8-8955-0242ac110012", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node ip-172-31-9-58.ec2.internal event: Registered Node ip-172-31-9-58.ec2.internal in Controller
2018-06-22T15:27:42.492482250Z I0622 15:27:42.492118       1 event.go:218] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-172-31-10-96.ec2.internal", UID:"3239d323-7590-11e8-8955-0242ac110012", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node ip-172-31-10-96.ec2.internal event: Registered Node ip-172-31-10-96.ec2.internal in Controller
2018-06-22T15:27:42.492486788Z W0622 15:27:42.492062       1 node_controller.go:920] Missing timestamp for Node ip-172-31-9-58.ec2.internal. Assuming now as a timestamp.
2018-06-22T15:27:42.492491375Z W0622 15:27:42.492173       1 node_controller.go:920] Missing timestamp for Node ip-172-31-10-96.ec2.internal. Assuming now as a timestamp.
2018-06-22T15:27:42.492494902Z I0622 15:27:42.492208       1 node_controller.go:836] Controller detected that zone  is now in state Normal.
2018-06-22T15:27:42.494966894Z I0622 15:27:42.494648       1 controller_utils.go:1048] Caches are synced for persistent volume controller
2018-06-22T15:27:42.503211518Z I0622 15:27:42.500367       1 controller_utils.go:1048] Caches are synced for job controller
2018-06-22T15:27:42.503229623Z I0622 15:27:42.500428       1 controller_utils.go:1048] Caches are synced for daemon sets controller
2018-06-22T15:27:42.506763426Z I0622 15:27:42.503698       1 controller_utils.go:1048] Caches are synced for deployment controller
2018-06-22T15:27:42.513016194Z I0622 15:27:42.509927       1 controller_utils.go:1048] Caches are synced for certificate controller
2018-06-22T15:27:42.513033879Z I0622 15:27:42.509919       1 controller_utils.go:1048] Caches are synced for endpoint controller
2018-06-22T15:27:42.513039495Z I0622 15:27:42.509926       1 controller_utils.go:1048] Caches are synced for GC controller
2018-06-28T16:42:27.001044086Z I0628 16:42:26.998911       1 controllermanager.go:109] Version: v1.8.11-docker-8d637ae
2018-06-28T16:42:27.039662296Z I0628 16:42:27.038183       1 leaderelection.go:174] attempting to acquire leader lease...
2018-06-28T16:42:37.039823272Z E0628 16:42:37.039711       1 leaderelection.go:224] error retrieving resource lock kube-system/kube-controller-manager: Get https://proxy.local:6444/api/v1/namespaces/kube-system/endpoints/kube-controller-manager: net/http: TLS handshake timeout
2018-06-28T16:42:51.079790566Z E0628 16:42:51.079658       1 leaderelection.go:224] error retrieving resource lock kube-system/kube-controller-manager: Get https://proxy.local:6444/api/v1/namespaces/kube-system/endpoints/kube-controller-manager: net/http: TLS handshake timeout
2018-06-28T16:43:04.766523564Z E0628 16:43:04.766421       1 leaderelection.go:224] error retrieving resource lock kube-system/kube-controller-manager: Get https://proxy.local:6444/api/v1/namespaces/kube-system/endpoints/kube-controller-manager: net/http: TLS handshake timeout
2018-06-28T16:43:18.819917185Z E0628 16:43:18.819796       1 leaderelection.go:224] error retrieving resource lock kube-system/kube-controller-manager: Get https://proxy.local:6444/api/v1/namespaces/kube-system/endpoints/kube-controller-manager: net/http: TLS handshake timeout
2018-06-28T16:43:31.490037746Z E0628 16:43:31.489917       1 leaderelection.go:224] error retrieving resource lock kube-system/kube-controller-manager: Get https://proxy.local:6444/api/v1/namespaces/kube-system/endpoints/kube-controller-manager: net/http: TLS handshake timeout
2018-06-28T16:43:34.370023999Z I0628 16:43:34.368268       1 leaderelection.go:184] successfully acquired lease kube-system/kube-controller-manager
2018-06-28T16:43:34.371144711Z I0628 16:43:34.371035       1 event.go:218] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"kube-controller-manager", UID:"1e44023a-7590-11e8-8955-0242ac110012", APIVersion:"v1", ResourceVersion:"835265", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' ip-172-31-9-58.ec2.internal became leader
2018-06-28T16:43:34.468898931Z I0628 16:43:34.468798       1 plugins.go:101] No cloud provider specified.
2018-06-28T16:43:34.470855453Z W0628 16:43:34.470767       1 core.go:128] Unsuccessful parsing of cluster CIDR : invalid CIDR address: 
2018-06-28T16:43:34.470871979Z I0628 16:43:34.470786       1 core.go:131] Will not configure cloud provider routes for allocate-node-cidrs: false, configure-cloud-routes: true.
2018-06-28T16:43:34.470880354Z W0628 16:43:34.470795       1 controllermanager.go:488] Skipping "route"
2018-06-28T16:43:34.471792529Z I0628 16:43:34.470931       1 controller_utils.go:1041] Waiting for caches to sync for tokens controller
2018-06-28T16:43:34.485922808Z I0628 16:43:34.482499       1 controllermanager.go:491] Started "disruption"
2018-06-28T16:43:34.485961844Z I0628 16:43:34.485313       1 controllermanager.go:491] Started "cronjob"
2018-06-28T16:43:34.489187129Z I0628 16:43:34.486732       1 disruption.go:288] Starting disruption controller
2018-06-28T16:43:34.489205963Z I0628 16:43:34.486824       1 controller_utils.go:1041] Waiting for caches to sync for disruption controller
2018-06-28T16:43:34.489225197Z I0628 16:43:34.487660       1 cronjob_controller.go:98] Starting CronJob Manager
2018-06-28T16:43:34.499652310Z I0628 16:43:34.490146       1 controllermanager.go:491] Started "ttl"
2018-06-28T16:43:34.499669114Z W0628 16:43:34.490156       1 controllermanager.go:475] "bootstrapsigner" is disabled
2018-06-28T16:43:34.499676177Z W0628 16:43:34.490161       1 controllermanager.go:475] "tokencleaner" is disabled
2018-06-28T16:43:34.499682268Z E0628 16:43:34.491488       1 core.go:70] Failed to start service controller: WARNING: no cloud provider provided, services of type LoadBalancer will fail.
2018-06-28T16:43:34.499688320Z W0628 16:43:34.491498       1 controllermanager.go:488] Skipping "service"
2018-06-28T16:43:34.499694215Z I0628 16:43:34.492636       1 node_controller.go:249] Sending events to api server.
2018-06-28T16:43:34.499700095Z I0628 16:43:34.492741       1 taint_controller.go:158] Sending events to api server.
2018-06-28T16:43:34.499705783Z I0628 16:43:34.492810       1 controllermanager.go:491] Started "node"
2018-06-28T16:43:34.499711692Z W0628 16:43:34.494578       1 probe.go:215] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
2018-06-28T16:43:34.499717833Z E0628 16:43:34.494625       1 plugins.go:393] Error initializing dynamic plugin prober: Error (re-)creating driver directory: mkdir /usr/libexec: permission denied
2018-06-28T16:43:34.499724002Z I0628 16:43:34.494664       1 ttl_controller.go:116] Starting TTL controller
2018-06-28T16:43:34.499729759Z I0628 16:43:34.494687       1 controller_utils.go:1041] Waiting for caches to sync for TTL controller
2018-06-28T16:43:34.499735648Z I0628 16:43:34.494840       1 node_controller.go:515] Starting node controller
2018-06-28T16:43:34.499741363Z I0628 16:43:34.494862       1 controller_utils.go:1041] Waiting for caches to sync for node controller
2018-06-28T16:43:34.499747139Z I0628 16:43:34.495284       1 controllermanager.go:491] Started "attachdetach"
2018-06-28T16:43:34.499765247Z I0628 16:43:34.495662       1 attach_detach_controller.go:255] Starting attach detach controller
2018-06-28T16:43:34.499780597Z I0628 16:43:34.495676       1 controller_utils.go:1041] Waiting for caches to sync for attach detach controller
2018-06-28T16:43:34.499786694Z I0628 16:43:34.496936       1 controllermanager.go:491] Started "job"
2018-06-28T16:43:34.499792607Z E0628 16:43:34.498217       1 certificates.go:48] Failed to start certificate controller: error reading CA cert file "/etc/kubernetes/ca/ca.pem": open /etc/kubernetes/ca/ca.pem: no such file or directory
2018-06-28T16:43:34.499799024Z W0628 16:43:34.498226       1 controllermanager.go:488] Skipping "csrsigning"
2018-06-28T16:43:34.506001615Z I0628 16:43:34.499263       1 job_controller.go:138] Starting job controller
2018-06-28T16:43:34.506018330Z I0628 16:43:34.499292       1 controller_utils.go:1041] Waiting for caches to sync for job controller
2018-06-28T16:43:34.506026134Z I0628 16:43:34.499665       1 controllermanager.go:491] Started "csrapproving"
2018-06-28T16:43:34.506042964Z I0628 16:43:34.501553       1 controllermanager.go:491] Started "endpoint"
2018-06-28T16:43:34.506049792Z I0628 16:43:34.502339       1 certificate_controller.go:109] Starting certificate controller
2018-06-28T16:43:34.506055819Z I0628 16:43:34.502364       1 controller_utils.go:1041] Waiting for caches to sync for certificate controller
2018-06-28T16:43:34.506061870Z I0628 16:43:34.502619       1 endpoints_controller.go:153] Starting endpoint controller
2018-06-28T16:43:34.506067797Z I0628 16:43:34.502642       1 controller_utils.go:1041] Waiting for caches to sync for endpoint controller
2018-06-28T16:43:34.506073880Z I0628 16:43:34.504853       1 controllermanager.go:491] Started "serviceaccount"
2018-06-28T16:43:34.507324266Z I0628 16:43:34.506692       1 serviceaccounts_controller.go:113] Starting service account controller
2018-06-28T16:43:34.507341062Z I0628 16:43:34.506714       1 controller_utils.go:1041] Waiting for caches to sync for service account controller
2018-06-28T16:43:34.574295121Z I0628 16:43:34.571663       1 controller_utils.go:1048] Caches are synced for tokens controller
2018-06-28T16:43:36.001589591Z I0628 16:43:35.988684       1 controllermanager.go:491] Started "garbagecollector"
2018-06-28T16:43:36.011006215Z I0628 16:43:36.010086       1 garbagecollector.go:136] Starting garbage collector controller
2018-06-28T16:43:36.011023222Z I0628 16:43:36.010119       1 controller_utils.go:1041] Waiting for caches to sync for garbage collector controller
2018-06-28T16:43:36.011030443Z I0628 16:43:36.010168       1 graph_builder.go:322] GraphBuilder running
2018-06-28T16:43:36.223043223Z I0628 16:43:36.218842       1 controllermanager.go:491] Started "deployment"
2018-06-28T16:43:36.257995050Z I0628 16:43:36.228780       1 deployment_controller.go:151] Starting deployment controller
2018-06-28T16:43:36.258012065Z I0628 16:43:36.228813       1 controller_utils.go:1041] Waiting for caches to sync for deployment controller
2018-06-28T16:43:36.410018501Z I0628 16:43:36.386323       1 controllermanager.go:491] Started "horizontalpodautoscaling"
2018-06-28T16:43:36.410926227Z I0628 16:43:36.410630       1 horizontal.go:145] Starting HPA controller
2018-06-28T16:43:36.410943092Z I0628 16:43:36.410701       1 controller_utils.go:1041] Waiting for caches to sync for HPA controller
2018-06-28T16:43:36.518987236Z I0628 16:43:36.513738       1 controllermanager.go:491] Started "persistentvolume-binder"
2018-06-28T16:43:36.519007636Z W0628 16:43:36.513761       1 controllermanager.go:488] Skipping "persistentvolume-expander"
2018-06-28T16:43:36.546071583Z I0628 16:43:36.545669       1 pv_controller_base.go:259] Starting persistent volume controller
2018-06-28T16:43:36.546088738Z I0628 16:43:36.545698       1 controller_utils.go:1041] Waiting for caches to sync for persistent volume controller
2018-06-28T16:43:36.762066410Z I0628 16:43:36.761660       1 controllermanager.go:491] Started "replicationcontroller"
2018-06-28T16:43:36.833980700Z I0628 16:43:36.833735       1 replication_controller.go:151] Starting RC controller
2018-06-28T16:43:36.834028169Z I0628 16:43:36.833766       1 controller_utils.go:1041] Waiting for caches to sync for RC controller
2018-06-28T16:43:37.021257473Z I0628 16:43:37.020794       1 controllermanager.go:491] Started "podgc"
2018-06-28T16:43:37.029024457Z W0628 16:43:37.028369       1 shared_informer.go:304] resyncPeriod 70754197476142 is smaller than resyncCheckPeriod 76550739583712 and the informer has already started. Changing it to 76550739583712
2018-06-28T16:43:37.029041937Z I0628 16:43:37.028448       1 controllermanager.go:491] Started "resourcequota"
2018-06-28T16:43:37.063010002Z I0628 16:43:37.062034       1 gc_controller.go:76] Starting GC controller
2018-06-28T16:43:37.063025231Z I0628 16:43:37.062060       1 controller_utils.go:1041] Waiting for caches to sync for GC controller
2018-06-28T16:43:37.098219602Z I0628 16:43:37.089979       1 resource_quota_controller.go:238] Starting resource quota controller
2018-06-28T16:43:37.098243819Z I0628 16:43:37.090008       1 controller_utils.go:1041] Waiting for caches to sync for resource quota controller
2018-06-28T16:43:38.530267336Z I0628 16:43:38.526107       1 controllermanager.go:491] Started "namespace"
2018-06-28T16:43:38.530300535Z I0628 16:43:38.526518       1 namespace_controller.go:186] Starting namespace controller
2018-06-28T16:43:38.530310604Z I0628 16:43:38.526535       1 controller_utils.go:1041] Waiting for caches to sync for namespace controller
2018-06-28T16:43:38.532708759Z I0628 16:43:38.532615       1 controllermanager.go:491] Started "daemonset"
2018-06-28T16:43:38.533026402Z I0628 16:43:38.532933       1 daemon_controller.go:230] Starting daemon sets controller
2018-06-28T16:43:38.533041441Z I0628 16:43:38.532969       1 controller_utils.go:1041] Waiting for caches to sync for daemon sets controller
2018-06-28T16:43:38.536875594Z I0628 16:43:38.536784       1 controllermanager.go:491] Started "replicaset"
2018-06-28T16:43:38.540111759Z I0628 16:43:38.538677       1 controllermanager.go:491] Started "statefulset"
2018-06-28T16:43:38.540129779Z I0628 16:43:38.539207       1 replica_set.go:156] Starting replica set controller
2018-06-28T16:43:38.540137279Z I0628 16:43:38.539229       1 controller_utils.go:1041] Waiting for caches to sync for replica set controller
2018-06-28T16:43:38.540143593Z I0628 16:43:38.539270       1 stateful_set.go:150] Starting stateful set controller
2018-06-28T16:43:38.540150067Z I0628 16:43:38.539287       1 controller_utils.go:1041] Waiting for caches to sync for stateful set controller
2018-06-28T16:43:38.570904319Z E0628 16:43:38.570463       1 actual_state_of_world.go:483] Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-10-96.ec2.internal"  does not exist
2018-06-28T16:43:38.570927616Z E0628 16:43:38.570480       1 actual_state_of_world.go:497] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-10-96.ec2.internal"  does not exist
2018-06-28T16:43:38.570936128Z E0628 16:43:38.570495       1 actual_state_of_world.go:483] Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-12-152.ec2.internal"  does not exist
2018-06-28T16:43:38.570974379Z E0628 16:43:38.570502       1 actual_state_of_world.go:497] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-12-152.ec2.internal"  does not exist
2018-06-28T16:43:38.570982844Z E0628 16:43:38.570660       1 actual_state_of_world.go:483] Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-18-229.ec2.internal"  does not exist
2018-06-28T16:43:38.570989636Z E0628 16:43:38.570670       1 actual_state_of_world.go:497] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-18-229.ec2.internal"  does not exist
2018-06-28T16:43:38.570996399Z E0628 16:43:38.570797       1 actual_state_of_world.go:483] Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-9-58.ec2.internal"  does not exist
2018-06-28T16:43:38.571002932Z E0628 16:43:38.570806       1 actual_state_of_world.go:497] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-9-58.ec2.internal"  does not exist
2018-06-28T16:43:38.598205634Z I0628 16:43:38.595754       1 controller_utils.go:1048] Caches are synced for TTL controller
2018-06-28T16:43:38.613646148Z I0628 16:43:38.612308       1 controller_utils.go:1048] Caches are synced for HPA controller
2018-06-28T16:43:38.648047916Z I0628 16:43:38.633186       1 controller_utils.go:1048] Caches are synced for namespace controller
2018-06-28T16:43:38.648823770Z I0628 16:43:38.648080       1 controller_utils.go:1048] Caches are synced for persistent volume controller
2018-06-28T16:43:38.665761338Z I0628 16:43:38.664144       1 controller_utils.go:1048] Caches are synced for GC controller
2018-06-28T16:43:38.691449638Z I0628 16:43:38.688196       1 controller_utils.go:1048] Caches are synced for disruption controller
2018-06-28T16:43:38.691478577Z I0628 16:43:38.688218       1 disruption.go:296] Sending events to api server.
2018-06-28T16:43:38.698154272Z I0628 16:43:38.694931       1 controller_utils.go:1048] Caches are synced for resource quota controller
2018-06-28T16:43:38.699802008Z I0628 16:43:38.698300       1 controller_utils.go:1048] Caches are synced for attach detach controller
2018-06-28T16:43:38.699819300Z I0628 16:43:38.698601       1 controller_utils.go:1048] Caches are synced for node controller
2018-06-28T16:43:38.699827201Z I0628 16:43:38.698711       1 node_controller.go:567] Initializing eviction metric for zone: 
2018-06-28T16:43:38.699833549Z W0628 16:43:38.698808       1 node_controller.go:920] Missing timestamp for Node ip-172-31-18-229.ec2.internal. Assuming now as a timestamp.
2018-06-28T16:43:38.699840281Z W0628 16:43:38.698873       1 node_controller.go:920] Missing timestamp for Node ip-172-31-9-58.ec2.internal. Assuming now as a timestamp.
2018-06-28T16:43:38.700161874Z W0628 16:43:38.698915       1 node_controller.go:920] Missing timestamp for Node ip-172-31-10-96.ec2.internal. Assuming now as a timestamp.
2018-06-28T16:43:38.700173516Z W0628 16:43:38.698986       1 node_controller.go:920] Missing timestamp for Node ip-172-31-12-152.ec2.internal. Assuming now as a timestamp.
2018-06-28T16:43:38.700187483Z I0628 16:43:38.699027       1 node_controller.go:836] Controller detected that zone  is now in state Normal.
2018-06-28T16:43:38.700194642Z I0628 16:43:38.699333       1 taint_controller.go:181] Starting NoExecuteTaintManager
2018-06-28T16:43:38.700201192Z I0628 16:43:38.699408       1 event.go:218] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-172-31-12-152.ec2.internal", UID:"31a722e9-7590-11e8-8955-0242ac110012", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node ip-172-31-12-152.ec2.internal event: Registered Node ip-172-31-12-152.ec2.internal in Controller
2018-06-28T16:43:38.700274225Z I0628 16:43:38.699432       1 event.go:218] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-172-31-18-229.ec2.internal", UID:"31ca3f1d-7590-11e8-8955-0242ac110012", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node ip-172-31-18-229.ec2.internal event: Registered Node ip-172-31-18-229.ec2.internal in Controller
2018-06-28T16:43:38.700285114Z I0628 16:43:38.699449       1 event.go:218] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-172-31-9-58.ec2.internal", UID:"1e876bf6-7590-11e8-8955-0242ac110012", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node ip-172-31-9-58.ec2.internal event: Registered Node ip-172-31-9-58.ec2.internal in Controller
2018-06-28T16:43:38.700293381Z I0628 16:43:38.699465       1 event.go:218] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-172-31-10-96.ec2.internal", UID:"3239d323-7590-11e8-8955-0242ac110012", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node ip-172-31-10-96.ec2.internal event: Registered Node ip-172-31-10-96.ec2.internal in Controller
2018-06-28T16:43:38.700301258Z I0628 16:43:38.699938       1 controller_utils.go:1048] Caches are synced for job controller
2018-06-28T16:43:38.704346692Z I0628 16:43:38.704087       1 controller_utils.go:1048] Caches are synced for endpoint controller
2018-06-28T16:43:38.704363337Z I0628 16:43:38.704144       1 controller_utils.go:1048] Caches are synced for certificate controller
2018-06-28T16:43:38.710188901Z I0628 16:43:38.710105       1 controller_utils.go:1048] Caches are synced for service account controller
2018-06-28T16:43:38.715339826Z I0628 16:43:38.714063       1 controller_utils.go:1048] Caches are synced for garbage collector controller
2018-06-28T16:43:38.715357246Z I0628 16:43:38.714079       1 garbagecollector.go:145] Garbage collector: all resource monitors have synced. Proceeding to collect garbage
2018-06-28T16:43:38.737167308Z I0628 16:43:38.734497       1 controller_utils.go:1048] Caches are synced for deployment controller
2018-06-28T16:43:38.738668282Z I0628 16:43:38.738017       1 controller_utils.go:1048] Caches are synced for RC controller
2018-06-28T16:43:38.738686581Z I0628 16:43:38.738055       1 controller_utils.go:1048] Caches are synced for daemon sets controller
2018-06-28T16:43:38.740700909Z I0628 16:43:38.740088       1 controller_utils.go:1048] Caches are synced for stateful set controller
2018-06-28T16:43:38.740717071Z I0628 16:43:38.740133       1 controller_utils.go:1048] Caches are synced for replica set controller
2018-06-28T16:56:31.567293164Z W0628 16:56:31.565848       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Deployment ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.567316685Z W0628 16:56:31.565973       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PersistentVolumeClaim ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.567325471Z W0628 16:56:31.566084       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.PodDisruptionBudget ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.567332579Z W0628 16:56:31.566180       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Endpoints ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.567339471Z W0628 16:56:31.566271       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Service ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.585520025Z W0628 16:56:31.585414       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.ControllerRevision ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.585591436Z W0628 16:56:31.585536       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.CertificateSigningRequest ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.585699920Z W0628 16:56:31.585632       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ReplicationController ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.585800582Z W0628 16:56:31.585737       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ServiceAccount ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590134519Z W0628 16:56:31.585844       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.CronJob ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590151820Z W0628 16:56:31.585966       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.LimitRange ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590173528Z W0628 16:56:31.586063       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PodTemplate ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590181041Z W0628 16:56:31.586167       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Secret ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590188169Z W0628 16:56:31.586257       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.PodSecurityPolicy ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590195042Z W0628 16:56:31.586347       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ConfigMap ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590203037Z W0628 16:56:31.586435       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.NetworkPolicy ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590210034Z W0628 16:56:31.586526       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1alpha1.InitializerConfiguration ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590217460Z W0628 16:56:31.586613       1 reflector.go:334] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: watch of <nil> ended with: very short watch: k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590224801Z W0628 16:56:31.586701       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.ResourceQuota ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590248873Z W0628 16:56:31.586792       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Deployment ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590256139Z W0628 16:56:31.586882       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.DaemonSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590268128Z W0628 16:56:31.586987       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.Ingress ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590275709Z W0628 16:56:31.587081       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Namespace ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590282611Z W0628 16:56:31.587175       1 reflector.go:334] k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: watch of <nil> ended with: very short watch: k8s.io/kubernetes/pkg/controller/garbagecollector/graph_builder.go:124: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590289797Z W0628 16:56:31.587264       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Job ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590296634Z W0628 16:56:31.587351       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta2.DaemonSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590303452Z W0628 16:56:31.587438       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Node ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590310574Z W0628 16:56:31.587525       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.Pod ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590318075Z W0628 16:56:31.587616       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.StorageClass ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590325116Z W0628 16:56:31.587707       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.ReplicaSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590331863Z W0628 16:56:31.587792       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.PersistentVolume ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590338893Z W0628 16:56:31.587882       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1alpha1.ExternalAdmissionHookConfiguration ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590349682Z W0628 16:56:31.588008       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta1.StatefulSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590356755Z W0628 16:56:31.588102       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1.HorizontalPodAutoscaler ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:31.590364075Z W0628 16:56:31.588197       1 reflector.go:334] k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: watch of *v1beta2.ReplicaSet ended with: very short watch: k8s.io/kubernetes/vendor/k8s.io/client-go/informers/factory.go:73: Unexpected watch close - watch lasted less than a second and no items received
2018-06-28T16:56:50.934971249Z I0628 16:56:50.928283       1 controllermanager.go:109] Version: v1.8.11-docker-8d637ae
2018-06-28T16:56:51.019997774Z I0628 16:56:50.987229       1 leaderelection.go:174] attempting to acquire leader lease...
2018-06-28T16:57:00.990450995Z E0628 16:57:00.990169       1 leaderelection.go:224] error retrieving resource lock kube-system/kube-controller-manager: Get https://proxy.local:6444/api/v1/namespaces/kube-system/endpoints/kube-controller-manager: net/http: TLS handshake timeout
2018-06-28T16:57:14.734221570Z E0628 16:57:14.733966       1 leaderelection.go:224] error retrieving resource lock kube-system/kube-controller-manager: Get https://proxy.local:6444/api/v1/namespaces/kube-system/endpoints/kube-controller-manager: net/http: TLS handshake timeout
2018-06-28T16:57:24.359397571Z I0628 16:57:24.359051       1 leaderelection.go:184] successfully acquired lease kube-system/kube-controller-manager
2018-06-28T16:57:24.359698233Z I0628 16:57:24.359365       1 event.go:218] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"kube-controller-manager", UID:"1e44023a-7590-11e8-8955-0242ac110012", APIVersion:"v1", ResourceVersion:"836475", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' ip-172-31-9-58.ec2.internal became leader
2018-06-28T16:57:24.407473759Z I0628 16:57:24.407207       1 plugins.go:101] No cloud provider specified.
2018-06-28T16:57:24.409301415Z I0628 16:57:24.409026       1 controller_utils.go:1041] Waiting for caches to sync for tokens controller
2018-06-28T16:57:24.413344523Z I0628 16:57:24.412645       1 node_controller.go:249] Sending events to api server.
2018-06-28T16:57:24.413361905Z I0628 16:57:24.412855       1 taint_controller.go:158] Sending events to api server.
2018-06-28T16:57:24.414667918Z I0628 16:57:24.413114       1 controllermanager.go:491] Started "node"
2018-06-28T16:57:24.414801821Z I0628 16:57:24.414675       1 node_controller.go:515] Starting node controller
2018-06-28T16:57:24.414815885Z I0628 16:57:24.414701       1 controller_utils.go:1041] Waiting for caches to sync for node controller
2018-06-28T16:57:24.417514561Z I0628 16:57:24.417278       1 controllermanager.go:491] Started "job"
2018-06-28T16:57:24.418907626Z I0628 16:57:24.418653       1 controllermanager.go:491] Started "disruption"
2018-06-28T16:57:24.419267820Z I0628 16:57:24.419171       1 job_controller.go:138] Starting job controller
2018-06-28T16:57:24.419282970Z I0628 16:57:24.419203       1 controller_utils.go:1041] Waiting for caches to sync for job controller
2018-06-28T16:57:24.419553105Z I0628 16:57:24.419326       1 disruption.go:288] Starting disruption controller
2018-06-28T16:57:24.419565068Z I0628 16:57:24.419347       1 controller_utils.go:1041] Waiting for caches to sync for disruption controller
2018-06-28T16:57:24.420312290Z E0628 16:57:24.420084       1 core.go:70] Failed to start service controller: WARNING: no cloud provider provided, services of type LoadBalancer will fail.
2018-06-28T16:57:24.420326266Z W0628 16:57:24.420100       1 controllermanager.go:488] Skipping "service"
2018-06-28T16:57:24.421626029Z I0628 16:57:24.421287       1 controllermanager.go:491] Started "replicationcontroller"
2018-06-28T16:57:24.421638656Z I0628 16:57:24.421466       1 replication_controller.go:151] Starting RC controller
2018-06-28T16:57:24.421642454Z I0628 16:57:24.421487       1 controller_utils.go:1041] Waiting for caches to sync for RC controller
2018-06-28T16:57:24.422667052Z I0628 16:57:24.422433       1 controllermanager.go:491] Started "cronjob"
2018-06-28T16:57:24.422681153Z W0628 16:57:24.422452       1 controllermanager.go:488] Skipping "persistentvolume-expander"
2018-06-28T16:57:24.423008357Z I0628 16:57:24.422675       1 cronjob_controller.go:98] Starting CronJob Manager
2018-06-28T16:57:24.423960799Z I0628 16:57:24.423706       1 controllermanager.go:491] Started "deployment"
2018-06-28T16:57:24.424191884Z I0628 16:57:24.423959       1 deployment_controller.go:151] Starting deployment controller
2018-06-28T16:57:24.424206083Z I0628 16:57:24.424004       1 controller_utils.go:1041] Waiting for caches to sync for deployment controller
2018-06-28T16:57:24.428882473Z I0628 16:57:24.428647       1 controllermanager.go:491] Started "horizontalpodautoscaling"
2018-06-28T16:57:24.429648266Z I0628 16:57:24.429465       1 horizontal.go:145] Starting HPA controller
2018-06-28T16:57:24.429665085Z I0628 16:57:24.429493       1 controller_utils.go:1041] Waiting for caches to sync for HPA controller
2018-06-28T16:57:24.430886649Z I0628 16:57:24.430607       1 controllermanager.go:491] Started "statefulset"
2018-06-28T16:57:24.430902403Z I0628 16:57:24.430828       1 stateful_set.go:150] Starting stateful set controller
2018-06-28T16:57:24.430909622Z I0628 16:57:24.430858       1 controller_utils.go:1041] Waiting for caches to sync for stateful set controller
2018-06-28T16:57:24.432016132Z E0628 16:57:24.431779       1 certificates.go:48] Failed to start certificate controller: error reading CA cert file "/etc/kubernetes/ca/ca.pem": open /etc/kubernetes/ca/ca.pem: no such file or directory
2018-06-28T16:57:24.432033973Z W0628 16:57:24.431799       1 controllermanager.go:488] Skipping "csrsigning"
2018-06-28T16:57:24.433159965Z I0628 16:57:24.433073       1 controllermanager.go:491] Started "csrapproving"
2018-06-28T16:57:24.433601855Z I0628 16:57:24.433368       1 certificate_controller.go:109] Starting certificate controller
2018-06-28T16:57:24.433616066Z I0628 16:57:24.433400       1 controller_utils.go:1041] Waiting for caches to sync for certificate controller
2018-06-28T16:57:24.434472348Z I0628 16:57:24.434273       1 controllermanager.go:491] Started "podgc"
2018-06-28T16:57:24.434692479Z I0628 16:57:24.434485       1 gc_controller.go:76] Starting GC controller
2018-06-28T16:57:24.434705176Z I0628 16:57:24.434509       1 controller_utils.go:1041] Waiting for caches to sync for GC controller
2018-06-28T16:57:24.435991493Z W0628 16:57:24.435740       1 shared_informer.go:304] resyncPeriod 52458869352351 is smaller than resyncCheckPeriod 61871744920764 and the informer has already started. Changing it to 61871744920764
2018-06-28T16:57:24.436004823Z I0628 16:57:24.435814       1 controllermanager.go:491] Started "resourcequota"
2018-06-28T16:57:24.436322777Z I0628 16:57:24.436096       1 resource_quota_controller.go:238] Starting resource quota controller
2018-06-28T16:57:24.436335442Z I0628 16:57:24.436122       1 controller_utils.go:1041] Waiting for caches to sync for resource quota controller
2018-06-28T16:57:24.437384456Z I0628 16:57:24.437157       1 controllermanager.go:491] Started "daemonset"
2018-06-28T16:57:24.437397733Z W0628 16:57:24.437173       1 controllermanager.go:475] "bootstrapsigner" is disabled
2018-06-28T16:57:24.437734044Z I0628 16:57:24.437450       1 daemon_controller.go:230] Starting daemon sets controller
2018-06-28T16:57:24.437745036Z I0628 16:57:24.437499       1 controller_utils.go:1041] Waiting for caches to sync for daemon sets controller
2018-06-28T16:57:24.509560391Z I0628 16:57:24.509237       1 controller_utils.go:1048] Caches are synced for tokens controller
2018-06-28T16:57:25.248879330Z I0628 16:57:25.248634       1 controllermanager.go:491] Started "garbagecollector"
2018-06-28T16:57:25.249216003Z I0628 16:57:25.249004       1 garbagecollector.go:136] Starting garbage collector controller
2018-06-28T16:57:25.249231137Z I0628 16:57:25.249040       1 controller_utils.go:1041] Waiting for caches to sync for garbage collector controller
2018-06-28T16:57:25.249237822Z I0628 16:57:25.249088       1 graph_builder.go:322] GraphBuilder running
2018-06-28T16:57:25.250476692Z I0628 16:57:25.250310       1 controllermanager.go:491] Started "replicaset"
2018-06-28T16:57:25.251166597Z I0628 16:57:25.250919       1 replica_set.go:156] Starting replica set controller
2018-06-28T16:57:25.251180157Z I0628 16:57:25.250949       1 controller_utils.go:1041] Waiting for caches to sync for replica set controller
2018-06-28T16:57:25.252093175Z I0628 16:57:25.251879       1 controllermanager.go:491] Started "ttl"
2018-06-28T16:57:25.252107105Z W0628 16:57:25.251894       1 controllermanager.go:475] "tokencleaner" is disabled
2018-06-28T16:57:25.252113333Z W0628 16:57:25.251902       1 core.go:128] Unsuccessful parsing of cluster CIDR : invalid CIDR address: 
2018-06-28T16:57:25.252126053Z I0628 16:57:25.251914       1 core.go:131] Will not configure cloud provider routes for allocate-node-cidrs: false, configure-cloud-routes: true.
2018-06-28T16:57:25.252132486Z W0628 16:57:25.251919       1 controllermanager.go:488] Skipping "route"
2018-06-28T16:57:25.252505864Z I0628 16:57:25.252164       1 ttl_controller.go:116] Starting TTL controller
2018-06-28T16:57:25.252523105Z I0628 16:57:25.252191       1 controller_utils.go:1041] Waiting for caches to sync for TTL controller
2018-06-28T16:57:25.258596406Z I0628 16:57:25.255584       1 controllermanager.go:491] Started "endpoint"
2018-06-28T16:57:25.260062967Z I0628 16:57:25.259910       1 endpoints_controller.go:153] Starting endpoint controller
2018-06-28T16:57:25.264177594Z I0628 16:57:25.261855       1 controller_utils.go:1041] Waiting for caches to sync for endpoint controller
2018-06-28T16:57:25.358308600Z I0628 16:57:25.354074       1 controllermanager.go:491] Started "namespace"
2018-06-28T16:57:25.358331627Z I0628 16:57:25.355263       1 namespace_controller.go:186] Starting namespace controller
2018-06-28T16:57:25.358339454Z I0628 16:57:25.355277       1 controller_utils.go:1041] Waiting for caches to sync for namespace controller
2018-06-28T16:57:25.358345369Z I0628 16:57:25.355567       1 controllermanager.go:491] Started "serviceaccount"
2018-06-28T16:57:25.358351184Z I0628 16:57:25.355862       1 serviceaccounts_controller.go:113] Starting service account controller
2018-06-28T16:57:25.358356782Z I0628 16:57:25.355885       1 controller_utils.go:1041] Waiting for caches to sync for service account controller
2018-06-28T16:57:25.358362480Z I0628 16:57:25.357327       1 controllermanager.go:491] Started "persistentvolume-binder"
2018-06-28T16:57:25.366962229Z W0628 16:57:25.359014       1 probe.go:215] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
2018-06-28T16:57:25.366980623Z E0628 16:57:25.359063       1 plugins.go:393] Error initializing dynamic plugin prober: Error (re-)creating driver directory: mkdir /usr/libexec: permission denied
2018-06-28T16:57:25.366988156Z I0628 16:57:25.359223       1 controllermanager.go:491] Started "attachdetach"
2018-06-28T16:57:25.366993975Z I0628 16:57:25.359690       1 pv_controller_base.go:259] Starting persistent volume controller
2018-06-28T16:57:25.366999727Z I0628 16:57:25.359712       1 controller_utils.go:1041] Waiting for caches to sync for persistent volume controller
2018-06-28T16:57:25.369005687Z I0628 16:57:25.359756       1 attach_detach_controller.go:255] Starting attach detach controller
2018-06-28T16:57:25.369024097Z I0628 16:57:25.359766       1 controller_utils.go:1041] Waiting for caches to sync for attach detach controller
2018-06-28T16:57:25.433239230Z I0628 16:57:25.429830       1 controller_utils.go:1048] Caches are synced for HPA controller
2018-06-28T16:57:25.436358445Z E0628 16:57:25.433053       1 actual_state_of_world.go:483] Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-9-58.ec2.internal"  does not exist
2018-06-28T16:57:25.436379720Z E0628 16:57:25.433069       1 actual_state_of_world.go:497] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-9-58.ec2.internal"  does not exist
2018-06-28T16:57:25.436397326Z E0628 16:57:25.433618       1 actual_state_of_world.go:483] Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-10-96.ec2.internal"  does not exist
2018-06-28T16:57:25.436404903Z E0628 16:57:25.433629       1 actual_state_of_world.go:497] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-10-96.ec2.internal"  does not exist
2018-06-28T16:57:25.436411300Z E0628 16:57:25.433704       1 actual_state_of_world.go:483] Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-12-152.ec2.internal"  does not exist
2018-06-28T16:57:25.436417432Z E0628 16:57:25.433713       1 actual_state_of_world.go:497] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-12-152.ec2.internal"  does not exist
2018-06-28T16:57:25.436423446Z E0628 16:57:25.433743       1 actual_state_of_world.go:483] Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-18-229.ec2.internal"  does not exist
2018-06-28T16:57:25.436429185Z E0628 16:57:25.433751       1 actual_state_of_world.go:497] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true because nodeName="ip-172-31-18-229.ec2.internal"  does not exist
2018-06-28T16:57:25.436435467Z I0628 16:57:25.435454       1 controller_utils.go:1048] Caches are synced for certificate controller
2018-06-28T16:57:25.436441137Z I0628 16:57:25.435720       1 controller_utils.go:1048] Caches are synced for GC controller
2018-06-28T16:57:25.437814730Z I0628 16:57:25.436821       1 controller_utils.go:1048] Caches are synced for resource quota controller
2018-06-28T16:57:25.461734271Z I0628 16:57:25.452906       1 controller_utils.go:1048] Caches are synced for garbage collector controller
2018-06-28T16:57:25.461791774Z I0628 16:57:25.452922       1 garbagecollector.go:145] Garbage collector: all resource monitors have synced. Proceeding to collect garbage
2018-06-28T16:57:25.461801016Z I0628 16:57:25.453494       1 controller_utils.go:1048] Caches are synced for replica set controller
2018-06-28T16:57:25.461824772Z I0628 16:57:25.454961       1 controller_utils.go:1048] Caches are synced for TTL controller
2018-06-28T16:57:25.461830941Z I0628 16:57:25.457490       1 controller_utils.go:1048] Caches are synced for service account controller
2018-06-28T16:57:25.461836507Z I0628 16:57:25.457599       1 controller_utils.go:1048] Caches are synced for namespace controller
2018-06-28T16:57:25.471086822Z I0628 16:57:25.463046       1 controller_utils.go:1048] Caches are synced for endpoint controller
2018-06-28T16:57:25.471107303Z I0628 16:57:25.463094       1 controller_utils.go:1048] Caches are synced for persistent volume controller
2018-06-28T16:57:25.471114461Z I0628 16:57:25.463140       1 controller_utils.go:1048] Caches are synced for attach detach controller
2018-06-28T16:57:25.518289836Z I0628 16:57:25.517938       1 controller_utils.go:1048] Caches are synced for node controller
2018-06-28T16:57:25.518322566Z I0628 16:57:25.518039       1 taint_controller.go:181] Starting NoExecuteTaintManager
2018-06-28T16:57:25.521427117Z I0628 16:57:25.518590       1 node_controller.go:567] Initializing eviction metric for zone: 
2018-06-28T16:57:25.521444082Z W0628 16:57:25.518787       1 node_controller.go:920] Missing timestamp for Node ip-172-31-18-229.ec2.internal. Assuming now as a timestamp.
2018-06-28T16:57:25.521451043Z W0628 16:57:25.518930       1 node_controller.go:920] Missing timestamp for Node ip-172-31-9-58.ec2.internal. Assuming now as a timestamp.
2018-06-28T16:57:25.521456802Z W0628 16:57:25.519043       1 node_controller.go:920] Missing timestamp for Node ip-172-31-10-96.ec2.internal. Assuming now as a timestamp.
2018-06-28T16:57:25.521462577Z W0628 16:57:25.520449       1 node_controller.go:920] Missing timestamp for Node ip-172-31-12-152.ec2.internal. Assuming now as a timestamp.
2018-06-28T16:57:25.521468502Z I0628 16:57:25.520494       1 node_controller.go:836] Controller detected that zone  is now in state Normal.
2018-06-28T16:57:25.521474170Z I0628 16:57:25.520545       1 controller_utils.go:1048] Caches are synced for disruption controller
2018-06-28T16:57:25.521479996Z I0628 16:57:25.520554       1 disruption.go:296] Sending events to api server.
2018-06-28T16:57:25.521485596Z I0628 16:57:25.520641       1 controller_utils.go:1048] Caches are synced for job controller
2018-06-28T16:57:25.521491385Z I0628 16:57:25.520789       1 event.go:218] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-172-31-9-58.ec2.internal", UID:"1e876bf6-7590-11e8-8955-0242ac110012", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node ip-172-31-9-58.ec2.internal event: Registered Node ip-172-31-9-58.ec2.internal in Controller
2018-06-28T16:57:25.521499733Z I0628 16:57:25.520813       1 event.go:218] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-172-31-18-229.ec2.internal", UID:"31ca3f1d-7590-11e8-8955-0242ac110012", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node ip-172-31-18-229.ec2.internal event: Registered Node ip-172-31-18-229.ec2.internal in Controller
2018-06-28T16:57:25.521508654Z I0628 16:57:25.520828       1 event.go:218] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-172-31-10-96.ec2.internal", UID:"3239d323-7590-11e8-8955-0242ac110012", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node ip-172-31-10-96.ec2.internal event: Registered Node ip-172-31-10-96.ec2.internal in Controller
2018-06-28T16:57:25.521516339Z I0628 16:57:25.521026       1 event.go:218] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-172-31-12-152.ec2.internal", UID:"31a722e9-7590-11e8-8955-0242ac110012", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node ip-172-31-12-152.ec2.internal event: Registered Node ip-172-31-12-152.ec2.internal in Controller
2018-06-28T16:57:25.527671570Z I0628 16:57:25.524274       1 controller_utils.go:1048] Caches are synced for deployment controller
2018-06-28T16:57:25.527689730Z I0628 16:57:25.525884       1 controller_utils.go:1048] Caches are synced for RC controller
2018-06-28T16:57:25.534881364Z I0628 16:57:25.532798       1 controller_utils.go:1048] Caches are synced for stateful set controller
2018-06-28T16:57:25.539969028Z I0628 16:57:25.537713       1 controller_utils.go:1048] Caches are synced for daemon sets controller
2018-06-28T17:00:55.539681759Z I0628 17:00:55.539396       1 event.go:218] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-172-31-12-152.ec2.internal", UID:"31a722e9-7590-11e8-8955-0242ac110012", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeNotReady' Node ip-172-31-12-152.ec2.internal status is now: NodeNotReady
